"""
Agentç¼–æ’å™¨ - åè°ƒå„ä¸ªAgentå®Œæˆæ—¥æŠ¥ç”Ÿæˆ
"""
import os
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_ollama import OllamaLLM
from langgraph.graph import StateGraph, END

from agents.collector import CollectorAgent
from agents.analyzer import AnalyzerAgent
from agents.deduplicator import DeduplicatorAgent
from agents.reporter import ReporterAgent
from agents.fact_checker import FactCheckerAgent
from utils.state import AgentState


class DailyReportOrchestrator:
    """æ—¥æŠ¥ç”Ÿæˆç¼–æ’å™¨"""
    
    def __init__(self, config: dict):
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # æ ¹æ®é…ç½®åˆå§‹åŒ–LLM
        provider = config['llm']['provider'].lower()

        if provider == 'ollama':
            # ä½¿ç”¨æœ¬åœ°Ollamaæ¨¡å‹
            self.llm = OllamaLLM(
                model=config['llm']['model'],
                base_url=config['llm'].get('ollama_base_url', 'http://localhost:11434'),
                temperature=config['llm']['temperature']
            )
            self.logger.info(f"ä½¿ç”¨æœ¬åœ°Ollamaæ¨¡å‹: {config['llm']['model']}")

        elif provider in ['dashscope', 'openai']:
            # ä½¿ç”¨è¿œç¨‹API
            self.llm = ChatOpenAI(
                model=config['llm']['model'],
                temperature=config['llm']['temperature'],
                max_tokens=config['llm']['max_tokens'],
                openai_api_base=config['llm'].get('base_url'),
                openai_api_key=os.getenv('DASHSCOPE_API_KEY') or os.getenv('OPENAI_API_KEY')
            )
            self.logger.info(f"ä½¿ç”¨è¿œç¨‹APIæ¨¡å‹: {config['llm']['model']} ({provider})")

        else:
            raise ValueError(f"ä¸æ”¯æŒçš„LLMæä¾›å•†: {provider}ã€‚æ”¯æŒ: dashscope, openai, ollama")
        
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        self.embeddings = OpenAIEmbeddings(
            model=config['embedding']['model'],
            openai_api_base=config['embedding'].get('base_url'),
            openai_api_key=os.getenv('DASHSCOPE_API_KEY') or os.getenv('OPENAI_API_KEY')
        )
        
        # åˆå§‹åŒ–å„ä¸ªAgent
        self.collector = CollectorAgent(config, self.llm)
        self.fact_checker = FactCheckerAgent(config, self.llm)
        self.analyzer = AnalyzerAgent(config, self.llm)
        self.deduplicator = DeduplicatorAgent(config, self.embeddings)
        self.reporter = ReporterAgent(config, self.llm)
        
        # æ„å»ºå·¥ä½œæµ
        self.workflow = self._build_workflow()
    
    def _build_workflow(self) -> StateGraph:
        """æ„å»ºAgentå·¥ä½œæµ"""
        workflow = StateGraph(AgentState)

        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("collect", self._collect_node)
        # workflow.add_node("fact_check", self._fact_check_node)  # æš‚æ—¶ç¦ç”¨
        workflow.add_node("analyze", self._analyze_node)
        workflow.add_node("deduplicate", self._deduplicate_node)
        workflow.add_node("report", self._report_node)

        # å®šä¹‰æµç¨‹ï¼šcollect -> analyze -> deduplicate -> report (æš‚æ—¶è·³è¿‡fact_check)
        workflow.set_entry_point("collect")
        workflow.add_edge("collect", "analyze")
        workflow.add_edge("analyze", "deduplicate")
        workflow.add_edge("deduplicate", "report")
        workflow.add_edge("report", END)

        return workflow.compile()
    
    def _collect_node(self, state: AgentState) -> AgentState:
        """ä¿¡æ¯é‡‡é›†èŠ‚ç‚¹"""
        self.logger.info("ğŸ“¡ é˜¶æ®µ1: ä¿¡æ¯é‡‡é›†")
        raw_items = self.collector.collect()
        state['raw_items'] = raw_items
        state['stage'] = 'collected'
        self.logger.info(f"   æ”¶é›†åˆ° {len(raw_items)} æ¡åŸå§‹ä¿¡æ¯")
        return state

    def _fact_check_node(self, state: AgentState) -> AgentState:
        """äº‹å®æ£€æŸ¥èŠ‚ç‚¹"""
        self.logger.info("âœ… é˜¶æ®µ2: äº‹å®æ£€æŸ¥ä¸éªŒè¯")
        checked_items = self.fact_checker.check_facts(state['raw_items'])
        state['checked_items'] = checked_items
        state['stage'] = 'fact_checked'
        self.logger.info(f"   äº‹å®æ£€æŸ¥å®Œæˆï¼Œä¿ç•™ {len(checked_items)} æ¡çœŸå®å†…å®¹")
        return state

    def _analyze_node(self, state: AgentState) -> AgentState:
        """å†…å®¹åˆ†æèŠ‚ç‚¹"""
        self.logger.info("ğŸ” é˜¶æ®µ2: å†…å®¹åˆ†æä¸è¯„åˆ†")
        analyzed_items = self.analyzer.analyze(state['raw_items'])
        state['analyzed_items'] = analyzed_items
        state['stage'] = 'analyzed'
        self.logger.info(f"   åˆ†æå®Œæˆï¼Œä¿ç•™ {len(analyzed_items)} æ¡é«˜è´¨é‡å†…å®¹")
        return state
    
    def _deduplicate_node(self, state: AgentState) -> AgentState:
        """å»é‡èŠ‚ç‚¹"""
        self.logger.info("ğŸ”„ é˜¶æ®µ3: è¯­ä¹‰å»é‡")
        unique_items = self.deduplicator.deduplicate(state['analyzed_items'])
        state['unique_items'] = unique_items
        state['stage'] = 'deduplicated'
        self.logger.info(f"   å»é‡å®Œæˆï¼Œå‰©ä½™ {len(unique_items)} æ¡ç‹¬ç‰¹å†…å®¹")
        return state

    def _report_node(self, state: AgentState) -> AgentState:
        """æŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹"""
        self.logger.info("ğŸ“ é˜¶æ®µ4: ç”ŸæˆæŠ¥å‘Š")
        report_path = self.reporter.generate_report(state['unique_items'])
        state['report_path'] = report_path
        state['stage'] = 'completed'
        self.logger.info(f"   æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        return state
    
    def run(self) -> tuple[str, int]:
        """è¿è¡Œå®Œæ•´æµç¨‹
        
        Returns:
            tuple: (æŠ¥å‘Šè·¯å¾„, èµ„è®¯æ•°é‡)
        """
        # åˆå§‹åŒ–çŠ¶æ€
        initial_state = AgentState(
            raw_items=[],
            checked_items=[],
            analyzed_items=[],
            unique_items=[],
            stage='initialized',
            report_path='',
            timestamp=datetime.now()
        )

        # æ‰§è¡Œå·¥ä½œæµ
        final_state = self.workflow.invoke(initial_state)

        # è¿”å›æŠ¥å‘Šè·¯å¾„å’Œèµ„è®¯æ•°é‡
        items_count = len(final_state['unique_items'])
        return final_state['report_path'], items_count