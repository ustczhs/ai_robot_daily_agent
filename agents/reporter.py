"""
æŠ¥å‘Šç”ŸæˆAgent - ç”Ÿæˆç»“æ„åŒ–çš„æŠ€æœ¯æ—¥æŠ¥
"""

import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict
from collections import defaultdict
from langchain.prompts import ChatPromptTemplate

from utils.state import NewsItem


class ReporterAgent:
    """æŠ¥å‘Šç”ŸæˆAgent"""

    def __init__(self, config: dict, llm):
        self.config = config
        self.llm = llm
        self.logger = logging.getLogger(__name__)
        self.output_dir = Path(config['report']['output_dir'])
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # æ£€æŸ¥LLMç±»å‹ï¼Œé€‚é…ä¸åŒçš„æç¤ºè¯æ ¼å¼
        llm_type = type(llm).__name__
        self.is_ollama = 'Ollama' in llm_type
        
    def generate_report(self, items: List[NewsItem]) -> str:
        """ç”ŸæˆæŠ¥å‘Š"""
        # æŒ‰ç±»åˆ«åˆ†ç»„
        categorized = self._categorize_items(items)
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = self._build_report(categorized, items)
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = self._save_report(report_content)
        
        return str(report_path)
    
    def _categorize_items(self, items: List[NewsItem]) -> Dict[str, List[NewsItem]]:
        """æŒ‰ç±»åˆ«åˆ†ç»„"""
        categorized = defaultdict(list)
        
        for item in items:
            category = item.get('category', 'å…¶ä»–')
            categorized[category].append(item)
        
        # æŒ‰è´¨é‡åˆ†æ•°æ’åº
        for category in categorized:
            categorized[category].sort(
                key=lambda x: x.get('quality_score', 0),
                reverse=True
            )
        
        return dict(categorized)
    
    def _build_report(self, categorized: Dict[str, List[NewsItem]], all_items: List[NewsItem]) -> str:
        """æ„å»ºæŠ¥å‘Šå†…å®¹"""
        today = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        
        # æŠ¥å‘Šå¤´éƒ¨
        report = f"""# ğŸ¤– AIä¸æœºå™¨äººæŠ€æœ¯æ—¥æŠ¥

**æ—¥æœŸ**: {today}  
**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%H:%M:%S')}

---

## ğŸ“Š ä»Šæ—¥æ¦‚è§ˆ

- **æ”¶é›†èµ„è®¯**: {len(all_items)} æ¡
- **æŠ€æœ¯ç±»åˆ«**: {len(categorized)} ä¸ª
- **ä¿¡æ¯æ¥æº**: {len(set(item['source'] for item in all_items))} ä¸ª

---

## ğŸ”¥ æŠ€æœ¯åˆ†ç±»

"""
        
        # æŒ‰ç±»åˆ«ç”Ÿæˆå†…å®¹
        max_items = self.config['report']['max_items_per_category']
        
        for category, items in categorized.items():
            report += f"\n### {category}\n\n"
            
            for i, item in enumerate(items[:max_items], 1):
                # ç”Ÿæˆå¹½é»˜ç‚¹è¯„
                comment = self._generate_comment(item)
                # æ‰“å°è¾“å‡ºitemçš„å…¨éƒ¨contextå†…å®¹ä»¥ä¾›è°ƒè¯•
                self.logger.info(f"ç”Ÿæˆç‚¹è¯„ - content: {item['content']}...") 
                self.logger.info(f"ç”Ÿæˆç‚¹è¯„ - full_content: {item['full_content']}...")  
                report += f"{i}. **[{item['title']}]({item['url']})**\n"
                report += f"   - ğŸ“° æ¥æº: {item['source']}\n"
                report += f"   - â­ è¯„åˆ†: {item.get('quality_score', 0):.1f}/10\n"
                report += f"   - ğŸ’¬ ç®€ä»‹: {comment}\n\n"
        
        # ç”Ÿæˆåˆ†æéƒ¨åˆ†
        if self.config['report']['include_trend_analysis']:
            report += "\n---\n\n"
            report += self._generate_trend_analysis(all_items)
        
        if self.config['report']['include_insights']:
            report += "\n---\n\n"
            report += self._generate_insights(all_items)
        
        if self.config['report']['include_predictions']:
            report += "\n---\n\n"
            report += self._generate_predictions(all_items)
        
        # æŠ¥å‘Šå°¾éƒ¨
        report += f"\n---\n\n*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆ | ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
        
        return report
    
    def _generate_comment(self, item: NewsItem) -> str:
        """ç”Ÿæˆè¯¦ç»†ç‚¹è¯„å’Œå†…å®¹ä»‹ç»"""
        if self.is_ollama:
            # Ollamaä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²æç¤ºè¯
            from langchain.prompts import PromptTemplate         
            prompt = PromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼äº‹å®å¯¼å‘çš„æŠ€æœ¯å†…å®¹åˆ†æå¸ˆï¼ŒåªåŸºäºæä¾›çš„æ ‡é¢˜ã€å†…å®¹å’Œæ¥æºç”Ÿæˆä¸­æ–‡ç‚¹è¯„ã€‚ç»ä¸æ·»åŠ ä»»ä½•æœªåœ¨è¾“å…¥ä¸­æ˜ç¡®å‡ºç°çš„ä¿¡æ¯ã€‚æ¥æºï¼ˆå¦‚StoryHubï¼‰ä»…ä½œä¸ºå‘å¸ƒå¹³å°ï¼Œä¸è¦è¯¯è§£ä¸ºäº§å“æˆ–æŠ€æœ¯ã€‚

ä¸¥æ ¼è¦æ±‚ï¼š
1. å…ˆç”¨1-2å¥è¯å‡†ç¡®æ¦‚æ‹¬è¾“å…¥å†…å®¹ä¸­çš„æ ¸å¿ƒäº§å“ã€æŠ€æœ¯æˆ–åˆ›æ–°ç‚¹ï¼ˆå¿…é¡»ç›´æ¥å¼•ç”¨æˆ–ç´§å¯†æ”¹è¿°åŸæ–‡å…³é”®ç‚¹ï¼Œæ— ç»†èŠ‚æ—¶ç®€è¿°å‘å¸ƒäº‹å®ï¼‰
2. åˆ†æè¿™é¡¹æŠ€æœ¯çš„å®é™…æ„ä¹‰å’Œåº”ç”¨å‰æ™¯ï¼ˆ2-3å¥è¯ï¼Œåªè®¨è®ºåŸæ–‡ä¸­æ˜ç¡®æåŠçš„åœºæ™¯æˆ–å½±å“ï¼Œä½¿ç”¨å®šæ€§æè¿°ï¼Œé¿å…é‡åŒ–ï¼‰
3. ä¿æŒä¸“ä¸šæ€§ï¼Œçªå‡ºæŠ€æœ¯ä»·å€¼
4. æ€»é•¿åº¦æ§åˆ¶åœ¨100-150å­—ï¼Œç”¨ç®€ä½“ä¸­æ–‡è¾“å‡ºï¼Œå…³é”®å­—å¯ä»¥ç”¨è‹±æ–‡è¡¨ç¤º
5. ä¸¥ç¦æåŠä»»ä½•æ•°å­—ã€ç™¾åˆ†æ¯”æˆ–é‡åŒ–æŒ‡æ ‡ï¼Œé™¤éåŸæ–‡ä¸­æ˜ç¡®å‡ºç°å¹¶å¼•ç”¨æ¥æº
6. æ‰€æœ‰å†…å®¹å¿…é¡»100%åŸºäºæä¾›çš„{title}ã€{content}å’Œ{source}ï¼Œå¦‚æŠ€æœ¯ç»†èŠ‚æˆ–æ€§èƒ½æ•°æ®ä¸è¶³ï¼Œåˆ™ä½¿ç”¨å®šæ€§è¯­è¨€ï¼ˆå¦‚â€œæå‡æ•ˆç‡â€â€œæ”¹å–„ä½“éªŒâ€ï¼‰æè¿°ï¼Œé¿å…å…·ä½“æ•°å­—
7. å¦‚åŸæ–‡ä»…ä¸ºä¼ä¸šæ–°é—»å‘å¸ƒï¼Œæ— æ·±å±‚é‡åŒ–ç»†èŠ‚ï¼Œåªæè¿°ä¸»è¦ç‰¹æ€§ä¸æ½œåœ¨åº”ç”¨

ç¤ºä¾‹ï¼ˆä»…ä¾›ç»“æ„å‚è€ƒï¼‰ï¼š
"Lenovoé¢„è§ˆäº†Lenovo Qiraä¸ªäººAIä»£ç†ï¼Œæ”¯æŒè·¨è®¾å¤‡ä¸Šä¸‹æ–‡è¿ç»­æ€§ï¼Œå¸®åŠ©ç”¨æˆ·åœ¨PCã€å¹³æ¿å’Œæ‰‹æœºé—´æ— ç¼åˆ‡æ¢ä»»åŠ¡ã€‚è¯¥æŠ€æœ¯å¼ºè°ƒéšç§ä¼˜å…ˆçš„æ··åˆAIæ¶æ„ï¼Œåœ¨ä¼ä¸šæ··åˆåŠå…¬åœºæ™¯ä¸­æä¾›æ›´è‡ªç„¶çš„äº¤äº’ä½“éªŒã€‚é¢„è®¡å°†æ¨åŠ¨å¤šè®¾å¤‡ç”Ÿæ€çš„æ™ºèƒ½ååŒå‘å±•ã€‚"

ä¸¥ç¦ï¼š
1. æé€ ä»»ä½•æ•°æ®ã€æ•°å­—ã€ç™¾åˆ†æ¯”ã€æ€§èƒ½æŒ‡æ ‡ã€æŠ€æœ¯ç»†èŠ‚æˆ–äº§å“åç§°
2. å°†æ–°é—»æ¥æºå¹³å°è¯¯è§£ä¸ºæŠ€æœ¯äº§å“
3. å¼•å…¥è¾“å…¥ä¸­æœªæåŠçš„æŠ€æœ¯ç»†èŠ‚
4. ä½¿ç”¨æœªåœ¨åŸæ–‡å‡ºç°çš„é‡åŒ–è¯­è¨€ï¼ˆå¦‚â€œæå‡XX%â€ï¼‰
5. è¾“å‡ºä¸è¾“å…¥æ— å…³çš„å†…å®¹
6. å…¨è‹±æ–‡è¾“å‡º                                                  

æ ‡é¢˜ï¼š{title}
å†…å®¹ï¼š{content}
æ¥æºï¼š{source}

è¯·ç”ŸæˆæŠ€æœ¯ç‚¹è¯„ï¼š""")
        else:
            # å…¶ä»–LLMä½¿ç”¨ChatPromptTemplate
            prompt = PromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼äº‹å®å¯¼å‘çš„æŠ€æœ¯å†…å®¹åˆ†æå¸ˆï¼ŒåªåŸºäºæä¾›çš„æ ‡é¢˜ã€å†…å®¹å’Œæ¥æºç”Ÿæˆä¸­æ–‡ç‚¹è¯„ã€‚ç»ä¸æ·»åŠ ä»»ä½•æœªåœ¨è¾“å…¥ä¸­æ˜ç¡®å‡ºç°çš„ä¿¡æ¯ã€‚æ¥æºï¼ˆå¦‚StoryHubï¼‰ä»…ä½œä¸ºå‘å¸ƒå¹³å°ï¼Œä¸è¦è¯¯è§£ä¸ºäº§å“æˆ–æŠ€æœ¯ã€‚

ä¸¥æ ¼è¦æ±‚ï¼š
1. å…ˆç”¨1-2å¥è¯å‡†ç¡®æ¦‚æ‹¬è¾“å…¥å†…å®¹ä¸­çš„æ ¸å¿ƒäº§å“ã€æŠ€æœ¯æˆ–åˆ›æ–°ç‚¹ï¼ˆå¿…é¡»ç›´æ¥å¼•ç”¨æˆ–ç´§å¯†æ”¹è¿°åŸæ–‡å…³é”®ç‚¹ï¼Œæ— ç»†èŠ‚æ—¶ç®€è¿°å‘å¸ƒäº‹å®ï¼‰
2. åˆ†æè¿™é¡¹æŠ€æœ¯çš„å®é™…æ„ä¹‰å’Œåº”ç”¨å‰æ™¯ï¼ˆ2-3å¥è¯ï¼Œåªè®¨è®ºåŸæ–‡ä¸­æ˜ç¡®æåŠçš„åœºæ™¯æˆ–å½±å“ï¼Œä½¿ç”¨å®šæ€§æè¿°ï¼Œé¿å…é‡åŒ–ï¼‰
3. ä¿æŒä¸“ä¸šæ€§ï¼Œçªå‡ºæŠ€æœ¯ä»·å€¼
4. æ€»é•¿åº¦æ§åˆ¶åœ¨100-150å­—ï¼Œç”¨ç®€ä½“ä¸­æ–‡è¾“å‡ºï¼Œå…³é”®å­—å¯ä»¥ç”¨è‹±æ–‡è¡¨ç¤º
5. ä¸¥ç¦æåŠä»»ä½•æ•°å­—ã€ç™¾åˆ†æ¯”æˆ–é‡åŒ–æŒ‡æ ‡ï¼Œé™¤éåŸæ–‡ä¸­æ˜ç¡®å‡ºç°å¹¶å¼•ç”¨æ¥æº
6. æ‰€æœ‰å†…å®¹å¿…é¡»100%åŸºäºæä¾›çš„{title}ã€{content}å’Œ{source}ï¼Œå¦‚æŠ€æœ¯ç»†èŠ‚æˆ–æ€§èƒ½æ•°æ®ä¸è¶³ï¼Œåˆ™ä½¿ç”¨å®šæ€§è¯­è¨€ï¼ˆå¦‚â€œæå‡æ•ˆç‡â€â€œæ”¹å–„ä½“éªŒâ€ï¼‰æè¿°ï¼Œé¿å…å…·ä½“æ•°å­—
7. å¦‚åŸæ–‡ä»…ä¸ºä¼ä¸šæ–°é—»å‘å¸ƒï¼Œæ— æ·±å±‚é‡åŒ–ç»†èŠ‚ï¼Œåªæè¿°ä¸»è¦ç‰¹æ€§ä¸æ½œåœ¨åº”ç”¨

ç¤ºä¾‹ï¼ˆä»…ä¾›ç»“æ„å‚è€ƒï¼‰ï¼š
"Lenovoé¢„è§ˆäº†Lenovo Qiraä¸ªäººAIä»£ç†ï¼Œæ”¯æŒè·¨è®¾å¤‡ä¸Šä¸‹æ–‡è¿ç»­æ€§ï¼Œå¸®åŠ©ç”¨æˆ·åœ¨PCã€å¹³æ¿å’Œæ‰‹æœºé—´æ— ç¼åˆ‡æ¢ä»»åŠ¡ã€‚è¯¥æŠ€æœ¯å¼ºè°ƒéšç§ä¼˜å…ˆçš„æ··åˆAIæ¶æ„ï¼Œåœ¨ä¼ä¸šæ··åˆåŠå…¬åœºæ™¯ä¸­æä¾›æ›´è‡ªç„¶çš„äº¤äº’ä½“éªŒã€‚é¢„è®¡å°†æ¨åŠ¨å¤šè®¾å¤‡ç”Ÿæ€çš„æ™ºèƒ½ååŒå‘å±•ã€‚"

ä¸¥ç¦ï¼š
1. æé€ ä»»ä½•æ•°æ®ã€æ•°å­—ã€ç™¾åˆ†æ¯”ã€æ€§èƒ½æŒ‡æ ‡ã€æŠ€æœ¯ç»†èŠ‚æˆ–äº§å“åç§°
2. å°†æ–°é—»æ¥æºå¹³å°è¯¯è§£ä¸ºæŠ€æœ¯äº§å“
3. å¼•å…¥è¾“å…¥ä¸­æœªæåŠçš„æŠ€æœ¯ç»†èŠ‚
4. ä½¿ç”¨æœªåœ¨åŸæ–‡å‡ºç°çš„é‡åŒ–è¯­è¨€ï¼ˆå¦‚â€œæå‡XX%â€ï¼‰
5. è¾“å‡ºä¸è¾“å…¥æ— å…³çš„å†…å®¹
6. å…¨è‹±æ–‡è¾“å‡º                                                  

æ ‡é¢˜ï¼š{title}
å†…å®¹ï¼š{content}
æ¥æºï¼š{source}

è¯·ç”ŸæˆæŠ€æœ¯ç‚¹è¯„ï¼š""")

        try:
            chain = prompt | self.llm
            response = chain.invoke({
                "title": item['title'],
                "content": item['full_content'],
                "source": item.get('source', 'Unknown')
            })

            # è°ƒè¯•ä¿¡æ¯
            self.logger.debug(f"LLMç‚¹è¯„å“åº”ç±»å‹: {type(response)}")
            self.logger.debug(f"LLMç‚¹è¯„å“åº”å†…å®¹: {response}")

            # å¤„ç†ollamaå’Œopenaiçš„ä¸åŒå“åº”æ ¼å¼
            if self.is_ollama:
                # Ollamaè¿”å›å­—ç¬¦ä¸²
                if isinstance(response, str):
                    content = response.strip()
                elif hasattr(response, 'content') and response.content:
                    content = response.content.strip()
                else:
                    content = str(response).strip()
            else:
                # OpenAIè¿”å›å¯¹è±¡
                if hasattr(response, 'content') and response.content:
                    content = response.content.strip()
                else:
                    content = ""

            if content:
                return content
            else:
                self.logger.warning("LLMè¿”å›å†…å®¹ä¸ºç©º")
                return "å€¼å¾—å…³æ³¨çš„æŠ€æœ¯è¿›å±•"

        except Exception as e:
            self.logger.error(f"ç”Ÿæˆç‚¹è¯„å¤±è´¥: {str(e)}")
            return "å€¼å¾—å…³æ³¨çš„æŠ€æœ¯è¿›å±•"
    
    def _generate_trend_analysis(self, items: List[NewsItem]) -> str:
        """ç”Ÿæˆè¶‹åŠ¿åˆ†æ"""
        if self.is_ollama:
            from langchain.prompts import PromptTemplate
            prompt = PromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯è¶‹åŠ¿åˆ†æä¸“å®¶ã€‚åŸºäºä»Šæ—¥æ”¶é›†çš„æŠ€æœ¯èµ„è®¯ï¼Œåˆ†æå½“å‰çš„æŠ€æœ¯è¶‹åŠ¿ã€‚

è¦æ±‚ï¼š
1. è¯†åˆ«çƒ­ç‚¹è¯é¢˜å’ŒæŠ€æœ¯æ–¹å‘
2. åˆ†ææŠ€æœ¯å‘å±•è¶‹åŠ¿
3. 3-5ä¸ªè¦ç‚¹ï¼Œæ¯ä¸ª2-3å¥è¯
4. ä¸“ä¸šä½†æ˜“æ‡‚

ä»Šæ—¥èµ„è®¯æ ‡é¢˜ï¼š
{titles}

è¯·åˆ†ææŠ€æœ¯è¶‹åŠ¿ï¼š""")
        else:
            prompt = ChatPromptTemplate.from_messages([
                ("system", """ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯è¶‹åŠ¿åˆ†æä¸“å®¶ã€‚åŸºäºä»Šæ—¥æ”¶é›†çš„æŠ€æœ¯èµ„è®¯ï¼Œåˆ†æå½“å‰çš„æŠ€æœ¯è¶‹åŠ¿ã€‚

è¦æ±‚ï¼š
1. è¯†åˆ«çƒ­ç‚¹è¯é¢˜å’ŒæŠ€æœ¯æ–¹å‘
2. åˆ†ææŠ€æœ¯å‘å±•è¶‹åŠ¿
3. 3-5ä¸ªè¦ç‚¹ï¼Œæ¯ä¸ª2-3å¥è¯
4. ä¸“ä¸šä½†æ˜“æ‡‚
"""),
                ("user", "ä»Šæ—¥èµ„è®¯æ ‡é¢˜ï¼š\n{titles}\n\nè¯·åˆ†ææŠ€æœ¯è¶‹åŠ¿ï¼š")
            ])

        try:
            titles = "\n".join(f"- {item['title']}" for item in items[:20])
            chain = prompt | self.llm
            response = chain.invoke({"titles": titles})

            # å¤„ç†å“åº”æ ¼å¼
            if self.is_ollama:
                content = response.strip() if isinstance(response, str) else str(response).strip()
            else:
                content = response.content.strip()

            return f"## ğŸ“ˆ è¶‹åŠ¿åˆ†æ\n\n{content}\n"
        except Exception as e:
            self.logger.warning(f"ç”Ÿæˆè¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}")
            return ""
    
    def _generate_insights(self, items: List[NewsItem]) -> str:
        """ç”Ÿæˆå‰æ²¿æ´å¯Ÿ"""
        if self.is_ollama:
            from langchain.prompts import PromptTemplate
            prompt = PromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯æ´å¯Ÿä¸“å®¶ã€‚åŸºäºä»Šæ—¥èµ„è®¯ï¼Œæä¾›å‰æ²¿æ´å¯Ÿã€‚

è¦æ±‚ï¼š
1. å‘ç°ä¸æ˜æ˜¾ä½†é‡è¦çš„ä¿¡å·
2. è¿æ¥ä¸åŒé¢†åŸŸçš„æŠ€æœ¯
3. æå‡ºç‹¬ç‰¹è§‚ç‚¹
4. 2-4ä¸ªæ´å¯Ÿï¼Œæ¯ä¸ª2-3å¥è¯

ä»Šæ—¥èµ„è®¯ï¼š
{summaries}

è¯·æä¾›å‰æ²¿æ´å¯Ÿï¼š""")
        else:
            prompt = ChatPromptTemplate.from_messages([
                ("system", """ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯æ´å¯Ÿä¸“å®¶ã€‚åŸºäºä»Šæ—¥èµ„è®¯ï¼Œæä¾›å‰æ²¿æ´å¯Ÿã€‚

è¦æ±‚ï¼š
1. å‘ç°ä¸æ˜æ˜¾ä½†é‡è¦çš„ä¿¡å·
2. è¿æ¥ä¸åŒé¢†åŸŸçš„æŠ€æœ¯
3. æå‡ºç‹¬ç‰¹è§‚ç‚¹
4. 2-4ä¸ªæ´å¯Ÿï¼Œæ¯ä¸ª2-3å¥è¯
"""),
                ("user", "ä»Šæ—¥èµ„è®¯ï¼š\n{summaries}\n\nè¯·æä¾›å‰æ²¿æ´å¯Ÿï¼š")
            ])

        try:
            summaries = "\n".join(
                f"- [{item.get('category', 'æœªåˆ†ç±»')}] {item['title']}"
                for item in items[:15]
            )
            chain = prompt | self.llm
            response = chain.invoke({"summaries": summaries})

            # å¤„ç†å“åº”æ ¼å¼
            if self.is_ollama:
                content = response.strip() if isinstance(response, str) else str(response).strip()
            else:
                content = response.content.strip()

            return f"## ğŸ”® å‰æ²¿æ´å¯Ÿ\n\n{content}\n"
        except Exception as e:
            self.logger.warning(f"ç”Ÿæˆå‰æ²¿æ´å¯Ÿå¤±è´¥: {str(e)}")
            return ""
    
    def _generate_predictions(self, items: List[NewsItem]) -> str:
        """ç”Ÿæˆæ–¹å‘é¢„æµ‹"""
        if self.is_ollama:
            from langchain.prompts import PromptTemplate
            prompt = PromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯é¢„æµ‹ä¸“å®¶ã€‚åŸºäºä»Šæ—¥èµ„è®¯ï¼Œé¢„æµ‹æœªæ¥æŠ€æœ¯æ–¹å‘ã€‚

è¦æ±‚ï¼š
1. åŸºäºå½“å‰è¶‹åŠ¿æ¨æµ‹æœªæ¥å‘å±•
2. å…³æ³¨3-6ä¸ªæœˆçš„çŸ­æœŸé¢„æµ‹
3. 2-3ä¸ªé¢„æµ‹æ–¹å‘
4. æœ‰ç†æœ‰æ®ï¼Œé¿å…ç©ºæ³›

ä»Šæ—¥èµ„è®¯ç±»åˆ«åˆ†å¸ƒï¼š
{categories}

è¯·é¢„æµ‹æŠ€æœ¯æ–¹å‘ï¼š""")
        else:
            prompt = ChatPromptTemplate.from_messages([
                ("system", """ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯é¢„æµ‹ä¸“å®¶ã€‚åŸºäºä»Šæ—¥èµ„è®¯ï¼Œé¢„æµ‹æœªæ¥æŠ€æœ¯æ–¹å‘ã€‚

è¦æ±‚ï¼š
1. åŸºäºå½“å‰è¶‹åŠ¿æ¨æµ‹æœªæ¥å‘å±•
2. å…³æ³¨3-6ä¸ªæœˆçš„çŸ­æœŸé¢„æµ‹
3. 2-3ä¸ªé¢„æµ‹æ–¹å‘
4. æœ‰ç†æœ‰æ®ï¼Œé¿å…ç©ºæ³›
"""),
                ("user", "ä»Šæ—¥èµ„è®¯ç±»åˆ«åˆ†å¸ƒï¼š\n{categories}\n\nè¯·é¢„æµ‹æŠ€æœ¯æ–¹å‘ï¼š")
            ])

        try:
            # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
            category_count = defaultdict(int)
            for item in items:
                category_count[item.get('category', 'å…¶ä»–')] += 1

            categories = "\n".join(
                f"- {cat}: {count}æ¡"
                for cat, count in sorted(category_count.items(), key=lambda x: x[1], reverse=True)
            )

            chain = prompt | self.llm
            response = chain.invoke({"categories": categories})

            # å¤„ç†å“åº”æ ¼å¼
            if self.is_ollama:
                content = response.strip() if isinstance(response, str) else str(response).strip()
            else:
                content = response.content.strip()

            return f"## ğŸ¯ æ–¹å‘é¢„æµ‹\n\n{content}\n"
        except Exception as e:
            self.logger.warning(f"ç”Ÿæˆæ–¹å‘é¢„æµ‹å¤±è´¥: {str(e)}")
            return ""
    
    def _save_report(self, content: str) -> Path:
        """ä¿å­˜æŠ¥å‘Š"""
        filename = f"ai_robot_daily_{datetime.now().strftime('%Y%m%d')}.md"
        filepath = self.output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return filepath
