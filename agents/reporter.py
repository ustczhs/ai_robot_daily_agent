"""
æŠ¥å‘Šç”ŸæˆAgent - ç”Ÿæˆç»“æ„åŒ–çš„æŠ€æœ¯æ—¥æŠ¥
"""

import logging
from datetime import datetime
from pathlib import Path
from typing import List, Dict
from collections import defaultdict
from langchain.prompts import ChatPromptTemplate

from utils.state import NewsItem


class ReporterAgent:
    """æŠ¥å‘Šç”ŸæˆAgent"""
    
    def __init__(self, config: dict, llm):
        self.config = config
        self.llm = llm
        self.logger = logging.getLogger(__name__)
        self.output_dir = Path(config['report']['output_dir'])
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def generate_report(self, items: List[NewsItem]) -> str:
        """ç”ŸæˆæŠ¥å‘Š"""
        # æŒ‰ç±»åˆ«åˆ†ç»„
        categorized = self._categorize_items(items)
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = self._build_report(categorized, items)
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = self._save_report(report_content)
        
        return str(report_path)
    
    def _categorize_items(self, items: List[NewsItem]) -> Dict[str, List[NewsItem]]:
        """æŒ‰ç±»åˆ«åˆ†ç»„"""
        categorized = defaultdict(list)
        
        for item in items:
            category = item.get('category', 'å…¶ä»–')
            categorized[category].append(item)
        
        # æŒ‰è´¨é‡åˆ†æ•°æ’åº
        for category in categorized:
            categorized[category].sort(
                key=lambda x: x.get('quality_score', 0),
                reverse=True
            )
        
        return dict(categorized)
    
    def _build_report(self, categorized: Dict[str, List[NewsItem]], all_items: List[NewsItem]) -> str:
        """æ„å»ºæŠ¥å‘Šå†…å®¹"""
        today = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')
        
        # æŠ¥å‘Šå¤´éƒ¨
        report = f"""# ğŸ¤– AIä¸æœºå™¨äººæŠ€æœ¯æ—¥æŠ¥

**æ—¥æœŸ**: {today}  
**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%H:%M:%S')}

---

## ğŸ“Š ä»Šæ—¥æ¦‚è§ˆ

- **æ”¶é›†èµ„è®¯**: {len(all_items)} æ¡
- **æŠ€æœ¯ç±»åˆ«**: {len(categorized)} ä¸ª
- **ä¿¡æ¯æ¥æº**: {len(set(item['source'] for item in all_items))} ä¸ª

---

## ğŸ”¥ æŠ€æœ¯åˆ†ç±»

"""
        
        # æŒ‰ç±»åˆ«ç”Ÿæˆå†…å®¹
        max_items = self.config['report']['max_items_per_category']
        
        for category, items in categorized.items():
            report += f"\n### {category}\n\n"
            
            for i, item in enumerate(items[:max_items], 1):
                # ç”Ÿæˆå¹½é»˜ç‚¹è¯„
                comment = self._generate_comment(item)
                
                report += f"{i}. **[{item['title']}]({item['url']})**\n"
                report += f"   - ğŸ“° æ¥æº: {item['source']}\n"
                report += f"   - â­ è¯„åˆ†: {item.get('quality_score', 0):.1f}/10\n"
                report += f"   - ğŸ’¬ {comment}\n\n"
        
        # ç”Ÿæˆåˆ†æéƒ¨åˆ†
        if self.config['report']['include_trend_analysis']:
            report += "\n---\n\n"
            report += self._generate_trend_analysis(all_items)
        
        if self.config['report']['include_insights']:
            report += "\n---\n\n"
            report += self._generate_insights(all_items)
        
        if self.config['report']['include_predictions']:
            report += "\n---\n\n"
            report += self._generate_predictions(all_items)
        
        # æŠ¥å‘Šå°¾éƒ¨
        report += f"\n---\n\n*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆ | ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"
        
        return report
    
    def _generate_comment(self, item: NewsItem) -> str:
        """ç”Ÿæˆè¯¦ç»†ç‚¹è¯„å’Œå†…å®¹ä»‹ç»"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æŠ€æœ¯å†…å®¹åˆ†æå¸ˆï¼Œæ“…é•¿æ·±å…¥è§£è¯»æŠ€æœ¯èµ„è®¯ã€‚

è¦æ±‚ï¼š
1. å…ˆç”¨1-2å¥è¯æ¦‚æ‹¬æ ¸å¿ƒæŠ€æœ¯å†…å®¹å’Œåˆ›æ–°ç‚¹
2. åˆ†æè¿™é¡¹æŠ€æœ¯çš„å®é™…æ„ä¹‰å’Œåº”ç”¨å‰æ™¯ï¼ˆ2-3å¥è¯ï¼‰
3. ä¿æŒä¸“ä¸šæ€§ï¼Œçªå‡ºæŠ€æœ¯ä»·å€¼
4. æ€»é•¿åº¦æ§åˆ¶åœ¨100-150å­—

ç¤ºä¾‹ï¼š
"OpenAIå‘å¸ƒäº†GPT-4çš„ä¼˜åŒ–ç‰ˆæœ¬ï¼Œé€šè¿‡æ”¹è¿›æ³¨æ„åŠ›æœºåˆ¶å°†æ¨ç†èƒ½åŠ›æå‡äº†25%ã€‚è¿™é¡¹æŠ€æœ¯ä¸»è¦æ”¹è¿›äº†å¤šæ­¥éª¤æ¨ç†ä»»åŠ¡çš„å‡†ç¡®æ€§ï¼Œå¯¹äºå¤æ‚é—®é¢˜è§£å†³å’Œä»£ç ç”Ÿæˆæœ‰æ˜¾è‘—å¸®åŠ©ã€‚é¢„è®¡å°†åœ¨è‡ªåŠ¨ç¼–ç¨‹å’Œç§‘å­¦ç ”ç©¶é¢†åŸŸå¸¦æ¥æ–°çš„çªç ´ã€‚"

é‡ç‚¹å…³æ³¨ï¼š
- æŠ€æœ¯åˆ›æ–°çš„å…·ä½“å†…å®¹
- æ€§èƒ½æå‡çš„æ•°æ®
- å®é™…åº”ç”¨åœºæ™¯
- æ½œåœ¨å½±å“
"""),
            ("user", "æ ‡é¢˜ï¼š{title}\nå†…å®¹ï¼š{content}\næ¥æºï¼š{source}\n\nè¯·ç”Ÿæˆè¯¦ç»†çš„æŠ€æœ¯ç‚¹è¯„ï¼š")
        ])
        
        try:
            chain = prompt | self.llm
            response = chain.invoke({
                "title": item['title'],
                "content": item['content'][:200],
                "source": item.get('source', 'Unknown')
            })

            # è°ƒè¯•ä¿¡æ¯
            self.logger.debug(f"LLMç‚¹è¯„å“åº”ç±»å‹: {type(response)}")
            self.logger.debug(f"LLMç‚¹è¯„å“åº”å†…å®¹: {response}")

            if hasattr(response, 'content') and response.content:
                content = response.content.strip()
                if content:
                    return content
                else:
                    self.logger.warning("LLMè¿”å›å†…å®¹ä¸ºç©º")
            else:
                self.logger.warning(f"LLMå“åº”æ²¡æœ‰contentå±æ€§: {response}")

            return "å€¼å¾—å…³æ³¨çš„æŠ€æœ¯è¿›å±•"

        except Exception as e:
            self.logger.error(f"ç”Ÿæˆç‚¹è¯„å¤±è´¥: {str(e)}")
            return "å€¼å¾—å…³æ³¨çš„æŠ€æœ¯è¿›å±•"
    
    def _generate_trend_analysis(self, items: List[NewsItem]) -> str:
        """ç”Ÿæˆè¶‹åŠ¿åˆ†æ"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯è¶‹åŠ¿åˆ†æä¸“å®¶ã€‚åŸºäºä»Šæ—¥æ”¶é›†çš„æŠ€æœ¯èµ„è®¯ï¼Œåˆ†æå½“å‰çš„æŠ€æœ¯è¶‹åŠ¿ã€‚

è¦æ±‚ï¼š
1. è¯†åˆ«çƒ­ç‚¹è¯é¢˜å’ŒæŠ€æœ¯æ–¹å‘
2. åˆ†ææŠ€æœ¯å‘å±•è¶‹åŠ¿
3. 3-5ä¸ªè¦ç‚¹ï¼Œæ¯ä¸ª2-3å¥è¯
4. ä¸“ä¸šä½†æ˜“æ‡‚
"""),
            ("user", "ä»Šæ—¥èµ„è®¯æ ‡é¢˜ï¼š\n{titles}\n\nè¯·åˆ†ææŠ€æœ¯è¶‹åŠ¿ï¼š")
        ])
        
        try:
            titles = "\n".join(f"- {item['title']}" for item in items[:20])
            chain = prompt | self.llm
            response = chain.invoke({"titles": titles})
            
            return f"## ğŸ“ˆ è¶‹åŠ¿åˆ†æ\n\n{response.content.strip()}\n"
        except Exception as e:
            self.logger.warning(f"ç”Ÿæˆè¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}")
            return ""
    
    def _generate_insights(self, items: List[NewsItem]) -> str:
        """ç”Ÿæˆå‰æ²¿æ´å¯Ÿ"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯æ´å¯Ÿä¸“å®¶ã€‚åŸºäºä»Šæ—¥èµ„è®¯ï¼Œæä¾›å‰æ²¿æ´å¯Ÿã€‚

è¦æ±‚ï¼š
1. å‘ç°ä¸æ˜æ˜¾ä½†é‡è¦çš„ä¿¡å·
2. è¿æ¥ä¸åŒé¢†åŸŸçš„æŠ€æœ¯
3. æå‡ºç‹¬ç‰¹è§‚ç‚¹
4. 2-4ä¸ªæ´å¯Ÿï¼Œæ¯ä¸ª2-3å¥è¯
"""),
            ("user", "ä»Šæ—¥èµ„è®¯ï¼š\n{summaries}\n\nè¯·æä¾›å‰æ²¿æ´å¯Ÿï¼š")
        ])
        
        try:
            summaries = "\n".join(
                f"- [{item.get('category', 'æœªåˆ†ç±»')}] {item['title']}"
                for item in items[:15]
            )
            chain = prompt | self.llm
            response = chain.invoke({"summaries": summaries})
            
            return f"## ğŸ”® å‰æ²¿æ´å¯Ÿ\n\n{response.content.strip()}\n"
        except Exception as e:
            self.logger.warning(f"ç”Ÿæˆå‰æ²¿æ´å¯Ÿå¤±è´¥: {str(e)}")
            return ""
    
    def _generate_predictions(self, items: List[NewsItem]) -> str:
        """ç”Ÿæˆæ–¹å‘é¢„æµ‹"""
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯é¢„æµ‹ä¸“å®¶ã€‚åŸºäºä»Šæ—¥èµ„è®¯ï¼Œé¢„æµ‹æœªæ¥æŠ€æœ¯æ–¹å‘ã€‚

è¦æ±‚ï¼š
1. åŸºäºå½“å‰è¶‹åŠ¿æ¨æµ‹æœªæ¥å‘å±•
2. å…³æ³¨3-6ä¸ªæœˆçš„çŸ­æœŸé¢„æµ‹
3. 2-3ä¸ªé¢„æµ‹æ–¹å‘
4. æœ‰ç†æœ‰æ®ï¼Œé¿å…ç©ºæ³›
"""),
            ("user", "ä»Šæ—¥èµ„è®¯ç±»åˆ«åˆ†å¸ƒï¼š\n{categories}\n\nè¯·é¢„æµ‹æŠ€æœ¯æ–¹å‘ï¼š")
        ])
        
        try:
            # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
            category_count = defaultdict(int)
            for item in items:
                category_count[item.get('category', 'å…¶ä»–')] += 1
            
            categories = "\n".join(
                f"- {cat}: {count}æ¡"
                for cat, count in sorted(category_count.items(), key=lambda x: x[1], reverse=True)
            )
            
            chain = prompt | self.llm
            response = chain.invoke({"categories": categories})
            
            return f"## ğŸ¯ æ–¹å‘é¢„æµ‹\n\n{response.content.strip()}\n"
        except Exception as e:
            self.logger.warning(f"ç”Ÿæˆæ–¹å‘é¢„æµ‹å¤±è´¥: {str(e)}")
            return ""
    
    def _save_report(self, content: str) -> Path:
        """ä¿å­˜æŠ¥å‘Š"""
        filename = f"ai_robot_daily_{datetime.now().strftime('%Y%m%d')}.md"
        filepath = self.output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return filepath
