"""
æŠ¥å‘Šç”ŸæˆAgent - ç”Ÿæˆç»“æ„åŒ–çš„æŠ€æœ¯æ—¥æŠ¥
"""

import logging
import os
from datetime import datetime
from pathlib import Path
from typing import List, Dict
from collections import defaultdict
import asyncio
from langchain.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

from utils.state import NewsItem


class ReporterAgent:
    """æŠ¥å‘Šç”ŸæˆAgent"""

    def __init__(self, config: dict, llm):
        self.config = config
        self.llm = llm
        self.logger = logging.getLogger(__name__)
        self.output_dir = Path(config['report']['output_dir'])
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # æ£€æŸ¥LLMç±»å‹ï¼Œé€‚é…ä¸åŒçš„æç¤ºè¯æ ¼å¼
        llm_type = type(llm).__name__
        self.is_ollama = 'Ollama' in llm_type

        # åˆå§‹åŒ–è¿œç¨‹LLMç”¨äºåˆ†ææ–¹æ³•
        analysis_provider = self.config['report'].get('analysis_llm_provider', 'remote')
        if analysis_provider == 'remote':
            self.remote_llm = ChatOpenAI(
                model="qwen-max",  # ä½¿ç”¨qwen-maxè¿›è¡Œé«˜è´¨é‡åˆ†æ
                temperature=0.3,  # åˆ†æéœ€è¦æ›´ç¡®å®šæ€§çš„è¾“å‡º
                max_tokens=4000,
                openai_api_base=config['llm'].get('base_url'),
                openai_api_key=os.getenv('DASHSCOPE_API_KEY') or os.getenv('OPENAI_API_KEY')
            )
            self.logger.info("åˆ†ææ–¹æ³•å°†ä½¿ç”¨è¿œç¨‹LLM: qwen-max")
        else:
            # å¦‚æœé…ç½®ä¸ºollamaï¼Œåˆ™ä½¿ç”¨ä¼ å…¥çš„llm
            self.remote_llm = llm
            self.logger.info("åˆ†ææ–¹æ³•å°†ä½¿ç”¨æœ¬åœ°LLM: ollama")
        
    def generate_report(self, items: List[NewsItem]) -> str:
        """ç”ŸæˆæŠ¥å‘Š"""
        # æŒ‰ç±»åˆ«åˆ†ç»„
        categorized = self._categorize_items(items)
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = self._build_report(categorized, items)
        
        # ä¿å­˜æŠ¥å‘Š
        report_path = self._save_report(report_content)
        
        return str(report_path)
    
    def _categorize_items(self, items: List[NewsItem]) -> Dict[str, List[NewsItem]]:
        """æŒ‰ç±»åˆ«åˆ†ç»„"""
        categorized = defaultdict(list)
        
        for item in items:
            category = item.get('category', 'å…¶ä»–')
            categorized[category].append(item)
        
        # æŒ‰è´¨é‡åˆ†æ•°æ’åº
        for category in categorized:
            categorized[category].sort(
                key=lambda x: x.get('quality_score', 0),
                reverse=True
            )
        
        return dict(categorized)
    
    def _build_report(self, categorized: Dict[str, List[NewsItem]], all_items: List[NewsItem]) -> str:
        """æ„å»ºæŠ¥å‘Šå†…å®¹ï¼ˆå¹¶å‘ç‚¹è¯„ç”Ÿæˆç‰ˆæœ¬ï¼‰"""
        # ä½¿ç”¨å¼‚æ­¥æ–¹æ³•å¹¶å‘ç”Ÿæˆç‚¹è¯„
        try:
            # åˆ›å»ºæ–°çš„äº‹ä»¶å¾ªç¯æˆ–åœ¨ç°æœ‰å¾ªç¯ä¸­è¿è¡Œ
            try:
                loop = asyncio.get_event_loop()
                if loop.is_running():
                    # å¦‚æœå·²æœ‰è¿è¡Œä¸­çš„å¾ªç¯ï¼Œä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå™¨
                    import concurrent.futures
                    with concurrent.futures.ThreadPoolExecutor() as executor:
                        future = executor.submit(asyncio.run, self._build_report_async(categorized, all_items))
                        report_content = future.result()
                else:
                    report_content = asyncio.run(self._build_report_async(categorized, all_items))
            except RuntimeError:
                # æ²¡æœ‰äº‹ä»¶å¾ªç¯ï¼Œåˆ›å»ºæ–°çš„
                report_content = asyncio.run(self._build_report_async(categorized, all_items))

            return report_content
        except Exception as e:
            self.logger.error(f"å¼‚æ­¥æ„å»ºæŠ¥å‘Šå¤±è´¥ï¼Œå›é€€åˆ°åŒæ­¥æ¨¡å¼: {str(e)}")
            # å›é€€åˆ°åŒæ­¥æ¨¡å¼
            return self._build_report_sync(categorized, all_items)

    async def _build_report_async(self, categorized: Dict[str, List[NewsItem]], all_items: List[NewsItem]) -> str:
        """å¼‚æ­¥æ„å»ºæŠ¥å‘Šå†…å®¹"""
        today = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')

        # æŠ¥å‘Šå¤´éƒ¨
        report = f"""# ğŸ¤– AIä¸æœºå™¨äººæŠ€æœ¯æ—¥æŠ¥

**æ—¥æœŸ**: {today}
**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%H:%M:%S')}

---

## ğŸ“Š ä»Šæ—¥æ¦‚è§ˆ

- **æ”¶é›†èµ„è®¯**: {len(all_items)} æ¡
- **æŠ€æœ¯ç±»åˆ«**: {len(categorized)} ä¸ª
- **ä¿¡æ¯æ¥æº**: {len(set(item['source'] for item in all_items))} ä¸ª

---

## ğŸ”¥ æŠ€æœ¯åˆ†ç±»

"""

        # æ”¶é›†æ‰€æœ‰éœ€è¦ç”Ÿæˆç‚¹è¯„çš„æ¡ç›®
        items_to_comment = []
        for category, items in categorized.items():
            max_items = self.config['report']['max_items_per_category']
            items_to_comment.extend(items[:max_items])

        self.logger.info(f"å¼€å§‹å¹¶å‘ç”Ÿæˆ {len(items_to_comment)} æ¡ç‚¹è¯„")

        # å¹¶å‘ç”Ÿæˆæ‰€æœ‰ç‚¹è¯„
        comments_dict = await self._generate_comments_concurrent(items_to_comment)

        # æŒ‰ç±»åˆ«ç”Ÿæˆå†…å®¹
        max_items = self.config['report']['max_items_per_category']

        for category, items in categorized.items():
            report += f"\n### {category}\n\n"

            for i, item in enumerate(items[:max_items], 1):
                # ä»å¹¶å‘ç»“æœä¸­è·å–ç‚¹è¯„
                comment = comments_dict.get(item['url'])
                if comment is None:
                    self.logger.debug(f"è·³è¿‡éæŠ€æœ¯å†…å®¹: {item['title']}")
                    continue  # è·³è¿‡è¿™ä¸ªæ¡ç›®ï¼Œä¸è®¡å…¥æ€»æ•°

                # ç¿»è¯‘æ ‡é¢˜ä¸ºç®€ä½“ä¸­æ–‡
                translated_title = self._translate_title(item['title'])
                # æ‰“å°è¾“å‡ºitemçš„å…¨éƒ¨contextå†…å®¹ä»¥ä¾›è°ƒè¯•
                self.logger.info(f"ç”Ÿæˆç‚¹è¯„ - content: {item['content']}...")
                self.logger.info(f"ç”Ÿæˆç‚¹è¯„ - full_content: {item['full_content']}...")
                report += f"{i}. **[{translated_title}][{item['title']}]\n({item['url']})**\n"
                report += f"   - ğŸ“° æ¥æº: {item['source']}\n"

                # æ·»åŠ å‘å¸ƒæ—¶é—´æ˜¾ç¤º
                published_date = item.get('published_date')
                if published_date and isinstance(published_date, datetime):
                    # æ ¼å¼åŒ–ä¸ºä¸­æ–‡æ—¶é—´æ ¼å¼
                    time_str = published_date.strftime('%Yå¹´%mæœˆ%dæ—¥')
                    report += f"   - ğŸ•’ å‘å¸ƒæ—¶é—´: {time_str}\t"
                else:
                    report += f"   - ğŸ•’ å‘å¸ƒæ—¶é—´: æœªçŸ¥\t"

                report += f"   - â­ è¯„åˆ†: {item.get('quality_score', 0):.1f}/10\n"
                report += f"   - ğŸ’¬ ç®€ä»‹: {comment}\n\n"

        # ç”Ÿæˆåˆ†æéƒ¨åˆ†ï¼ˆè¿™äº›å¯ä»¥ä¸²è¡Œæ‰§è¡Œï¼Œå› ä¸ºé€šå¸¸æ•°é‡å°‘ï¼‰
        if self.config['report']['include_trend_analysis']:
            report += "\n---\n\n"
            report += self._generate_trend_analysis(all_items)

        if self.config['report']['include_insights']:
            report += "\n---\n\n"
            report += self._generate_insights(all_items)

        if self.config['report']['include_predictions']:
            report += "\n---\n\n"
            report += self._generate_predictions(all_items)

        # æŠ¥å‘Šå°¾éƒ¨
        report += f"\n---\n\n*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆ | ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"

        return report

    async def _generate_comments_concurrent(self, items: List[NewsItem]) -> Dict[str, str]:
        """å¹¶å‘ç”Ÿæˆå¤šä¸ªæ¡ç›®çš„ç‚¹è¯„"""
        comments_dict = {}

        # ä½¿ç”¨ä¿¡å·é‡æ§åˆ¶å¹¶å‘æ•°é‡ï¼Œé¿å…LLMæœåŠ¡è¿‡è½½
        semaphore = asyncio.Semaphore(8)  # æœ€å¤š8ä¸ªå¹¶å‘ç‚¹è¯„ç”Ÿæˆ

        async def generate_single_comment(item: NewsItem) -> tuple[str, str]:
            async with semaphore:
                try:
                    comment = await self._generate_comment_async(item)
                    return item['url'], comment
                except Exception as e:
                    self.logger.warning(f"å¼‚æ­¥ç”Ÿæˆç‚¹è¯„å¤±è´¥ {item['url']}: {str(e)}")
                    return item['url'], None

        # åˆ›å»ºæ‰€æœ‰ä»»åŠ¡
        tasks = [generate_single_comment(item) for item in items]

        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # å¤„ç†ç»“æœ
        for result in results:
            if isinstance(result, Exception):
                self.logger.error(f"å¼‚æ­¥ç‚¹è¯„ä»»åŠ¡æ‰§è¡Œå¼‚å¸¸: {str(result)}")
            else:
                url, comment = result
                comments_dict[url] = comment

        self.logger.info(f"å¹¶å‘ç‚¹è¯„ç”Ÿæˆå®Œæˆï¼Œå…±å¤„ç† {len(comments_dict)} æ¡")
        return comments_dict

    def _build_report_sync(self, categorized: Dict[str, List[NewsItem]], all_items: List[NewsItem]) -> str:
        """åŒæ­¥å›é€€æ–¹æ³•ï¼šæ„å»ºæŠ¥å‘Šå†…å®¹"""
        today = datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥')

        # æŠ¥å‘Šå¤´éƒ¨
        report = f"""# ğŸ¤– AIä¸æœºå™¨äººæŠ€æœ¯æ—¥æŠ¥

**æ—¥æœŸ**: {today}
**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%H:%M:%S')}

---

## ğŸ“Š ä»Šæ—¥æ¦‚è§ˆ

- **æ”¶é›†èµ„è®¯**: {len(all_items)} æ¡
- **æŠ€æœ¯ç±»åˆ«**: {len(categorized)} ä¸ª
- **ä¿¡æ¯æ¥æº**: {len(set(item['source'] for item in all_items))} ä¸ª

---

## ğŸ”¥ æŠ€æœ¯åˆ†ç±»

"""

        # æŒ‰ç±»åˆ«ç”Ÿæˆå†…å®¹
        max_items = self.config['report']['max_items_per_category']

        for category, items in categorized.items():
            report += f"\n### {category}\n\n"

            for i, item in enumerate(items[:max_items], 1):
                # ç”Ÿæˆç‚¹è¯„ï¼Œå¦‚æœä¸æŠ€æœ¯ç›¸å…³åˆ™è·³è¿‡
                comment = self._generate_comment(item)
                if comment is None:
                    self.logger.debug(f"è·³è¿‡éæŠ€æœ¯å†…å®¹: {item['title']}")
                    continue  # è·³è¿‡è¿™ä¸ªæ¡ç›®ï¼Œä¸è®¡å…¥æ€»æ•°

                # ç¿»è¯‘æ ‡é¢˜ä¸ºç®€ä½“ä¸­æ–‡
                translated_title = self._translate_title(item['title'])
                # æ‰“å°è¾“å‡ºitemçš„å…¨éƒ¨contextå†…å®¹ä»¥ä¾›è°ƒè¯•
                self.logger.info(f"ç”Ÿæˆç‚¹è¯„ - content: {item['content']}...")
                self.logger.info(f"ç”Ÿæˆç‚¹è¯„ - full_content: {item['full_content']}...")
                report += f"{i}. **[{translated_title}][{item['title']}]\n({item['url']})**\n"
                report += f"   - ğŸ“° æ¥æº: {item['source']}\n"

                # æ·»åŠ å‘å¸ƒæ—¶é—´æ˜¾ç¤º
                published_date = item.get('published_date')
                if published_date and isinstance(published_date, datetime):
                    # æ ¼å¼åŒ–ä¸ºä¸­æ–‡æ—¶é—´æ ¼å¼
                    time_str = published_date.strftime('%Yå¹´%mæœˆ%dæ—¥')
                    report += f"   - ğŸ•’ å‘å¸ƒæ—¶é—´: {time_str}\t"
                else:
                    report += f"   - ğŸ•’ å‘å¸ƒæ—¶é—´: æœªçŸ¥\t"

                report += f"   - â­ è¯„åˆ†: {item.get('quality_score', 0):.1f}/10\n"
                report += f"   - ğŸ’¬ ç®€ä»‹: {comment}\n\n"

        # ç”Ÿæˆåˆ†æéƒ¨åˆ†
        if self.config['report']['include_trend_analysis']:
            report += "\n---\n\n"
            report += self._generate_trend_analysis(all_items)

        if self.config['report']['include_insights']:
            report += "\n---\n\n"
            report += self._generate_insights(all_items)

        if self.config['report']['include_predictions']:
            report += "\n---\n\n"
            report += self._generate_predictions(all_items)

        # æŠ¥å‘Šå°¾éƒ¨
        report += f"\n---\n\n*æœ¬æŠ¥å‘Šç”±AIè‡ªåŠ¨ç”Ÿæˆ | ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*\n"

        return report
    
    def _translate_title(self, title: str) -> str:
        """ç¿»è¯‘æ ‡é¢˜ä¸ºç®€ä½“ä¸­æ–‡"""
        if not self.is_ollama:
            # å¦‚æœä¸æ˜¯ollamaï¼Œç›´æ¥è¿”å›åŸæ ‡é¢˜
            return title

        from langchain.prompts import PromptTemplate
        prompt = PromptTemplate.from_template("""è¯·å°†ä»¥ä¸‹æ ‡é¢˜ç¿»è¯‘ä¸ºç®€ä½“ä¸­æ–‡ï¼Œä¿æŒä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ã€‚åªè¾“å‡ºç¿»è¯‘åçš„æ ‡é¢˜ï¼Œä¸è¦æ·»åŠ ä»»ä½•å…¶ä»–å†…å®¹ã€‚

æ ‡é¢˜ï¼š{title}

ç¿»è¯‘ï¼š""")

        try:
            chain = prompt | self.llm
            response = chain.invoke({"title": title})

            # å¤„ç†ollamaå“åº”æ ¼å¼
            if isinstance(response, str):
                translated = response.strip()
            elif hasattr(response, 'content') and response.content:
                translated = response.content.strip()
            else:
                translated = str(response).strip()

            # æ¸…ç†å¯èƒ½çš„é¢å¤–å†…å®¹ï¼Œåªä¿ç•™ç¬¬ä¸€è¡Œ
            translated = translated.split('\n')[0].strip()

            if translated:
                return translated
            else:
                self.logger.warning(f"æ ‡é¢˜ç¿»è¯‘å¤±è´¥ï¼Œè¿”å›åŸæ ‡é¢˜: {title}")
                return title

        except Exception as e:
            self.logger.error(f"ç¿»è¯‘æ ‡é¢˜å¤±è´¥: {str(e)}")
            return title

    def _generate_comment(self, item: NewsItem) -> str:
        """ç”Ÿæˆè¯¦ç»†ç‚¹è¯„å’Œå†…å®¹ä»‹ç»"""
        if self.is_ollama:
            # Ollamaä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²æç¤ºè¯
            from langchain.prompts import PromptTemplate
            prompt = PromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯æ–°é—»æ‘˜è¦å™¨ã€‚åªæ ¹æ®æä¾›çš„æ ‡é¢˜ã€å†…å®¹ã€æ¥æºï¼Œç”¨ç®€ä½“ä¸­æ–‡å†™100-200å­—æŠ€æœ¯æ€»ç»“ã€‚
ä»»åŠ¡ï¼š
1. ç”Ÿæˆ100-200å­—æŠ€æœ¯ç‚¹è¯„ï¼ŒåŒ…å«æ ¸å¿ƒæŠ€æœ¯/äº§å“/åˆ›æ–°ç‚¹å’Œåº”ç”¨åœºæ™¯
2. åˆ¤æ–­å†…å®¹æ˜¯å¦ä¸æœºå™¨äºº/AI/è‡ªåŠ¨åŒ–çš„æŠ€æœ¯ç›´æ¥ç›¸å…³

ä¸¥ç¦æ·»åŠ åŸæ–‡æ²¡æœ‰çš„ä¿¡æ¯ã€ä»»ä½•æ•°å­—ã€æ€§èƒ½æŒ‡æ ‡ã€æ¨æµ‹å†…å®¹ã€‚

è¾“å‡ºæ ¼å¼ï¼š
ç‚¹è¯„ï¼š[100-200å­—æŠ€æœ¯æ€»ç»“]
æ˜¯å¦æŠ€æœ¯ç›¸å…³ï¼š[æ˜¯/å¦]
                                                  
æ ‡é¢˜ï¼š{title}
å†…å®¹ï¼š{content}
æ¥æºï¼š{source}

è¾“å‡ºï¼š""")
            # prompt = PromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯æ–°é—»æ‘˜è¦å™¨ã€‚åªæ ¹æ®æä¾›çš„æ ‡é¢˜ã€å†…å®¹ã€æ¥æºï¼Œç”¨ç®€ä½“ä¸­æ–‡å†™100-200å­—æŠ€æœ¯æ€»ç»“ï¼Œåªæ€»ç»“ä¸åˆ¤æ–­ã€‚

            # å¿…é¡»åŒ…å«ï¼š
            # - æ¦‚æ‹¬æ ¸å¿ƒæŠ€æœ¯/äº§å“/åˆ›æ–°ç‚¹
            # - 1-2å¥è¯´æ˜å®é™…æ„ä¹‰æˆ–åº”ç”¨åœºæ™¯ï¼ˆåªè¯´åŸæ–‡æåˆ°çš„ï¼‰
            # - é‡ç‚¹å…³æ³¨æåŠçš„äº§å“åç§°åŠç‰¹ç‚¹                                                  

            # ä¸¥ç¦æ·»åŠ åŸæ–‡æ²¡æœ‰çš„ä¿¡æ¯ã€ä»»ä½•æ•°å­—ã€æ€§èƒ½æŒ‡æ ‡ã€æ¨æµ‹å†…å®¹ã€‚

            # æ ‡é¢˜ï¼š{title}
            # å†…å®¹ï¼š{content}
            # æ¥æºï¼š{source}

            # è¾“å‡ºï¼š""")
        else:
            # å…¶ä»–LLMä½¿ç”¨ChatPromptTemplate
            prompt = PromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªä¸¥æ ¼äº‹å®å¯¼å‘çš„æŠ€æœ¯å†…å®¹åˆ†æå¸ˆï¼ŒåªåŸºäºæä¾›çš„æ ‡é¢˜ã€å†…å®¹å’Œæ¥æºç”Ÿæˆä¸­æ–‡ç‚¹è¯„ã€‚ç»ä¸æ·»åŠ ä»»ä½•æœªåœ¨è¾“å…¥ä¸­æ˜ç¡®å‡ºç°çš„ä¿¡æ¯ã€‚æ¥æºï¼ˆå¦‚StoryHubï¼‰ä»…ä½œä¸ºå‘å¸ƒå¹³å°ï¼Œä¸è¦è¯¯è§£ä¸ºäº§å“æˆ–æŠ€æœ¯ã€‚

ä¸¥æ ¼è¦æ±‚ï¼š
1. å…ˆç”¨1-2å¥è¯å‡†ç¡®æ¦‚æ‹¬è¾“å…¥å†…å®¹ä¸­çš„æ ¸å¿ƒäº§å“ã€æŠ€æœ¯æˆ–åˆ›æ–°ç‚¹ï¼ˆå¿…é¡»ç›´æ¥å¼•ç”¨æˆ–ç´§å¯†æ”¹è¿°åŸæ–‡å…³é”®ç‚¹ï¼Œæ— ç»†èŠ‚æ—¶ç®€è¿°å‘å¸ƒäº‹å®ï¼‰
2. åˆ†æè¿™é¡¹æŠ€æœ¯çš„å®é™…æ„ä¹‰å’Œåº”ç”¨å‰æ™¯ï¼ˆ2-3å¥è¯ï¼Œåªè®¨è®ºåŸæ–‡ä¸­æ˜ç¡®æåŠçš„åœºæ™¯æˆ–å½±å“ï¼Œä½¿ç”¨å®šæ€§æè¿°ï¼Œé¿å…é‡åŒ–ï¼‰
3. ä¿æŒä¸“ä¸šæ€§ï¼Œçªå‡ºæŠ€æœ¯ä»·å€¼
4. æ€»é•¿åº¦æ§åˆ¶åœ¨100-150å­—ï¼Œç”¨ç®€ä½“ä¸­æ–‡è¾“å‡ºï¼Œå…³é”®å­—å¯ä»¥ç”¨è‹±æ–‡è¡¨ç¤º
5. ä¸¥ç¦æåŠä»»ä½•æ•°å­—ã€ç™¾åˆ†æ¯”æˆ–é‡åŒ–æŒ‡æ ‡ï¼Œé™¤éåŸæ–‡ä¸­æ˜ç¡®å‡ºç°å¹¶å¼•ç”¨æ¥æº
6. æ‰€æœ‰å†…å®¹å¿…é¡»100%åŸºäºæä¾›çš„{title}ã€{content}å’Œ{source}ï¼Œå¦‚æŠ€æœ¯ç»†èŠ‚æˆ–æ€§èƒ½æ•°æ®ä¸è¶³ï¼Œåˆ™ä½¿ç”¨å®šæ€§è¯­è¨€ï¼ˆå¦‚â€œæå‡æ•ˆç‡â€â€œæ”¹å–„ä½“éªŒâ€ï¼‰æè¿°ï¼Œé¿å…å…·ä½“æ•°å­—
7. å¦‚åŸæ–‡ä»…ä¸ºä¼ä¸šæ–°é—»å‘å¸ƒï¼Œæ— æ·±å±‚é‡åŒ–ç»†èŠ‚ï¼Œåªæè¿°ä¸»è¦ç‰¹æ€§ä¸æ½œåœ¨åº”ç”¨

ç¤ºä¾‹ï¼ˆä»…ä¾›ç»“æ„å‚è€ƒï¼‰ï¼š
"Lenovoé¢„è§ˆäº†Lenovo Qiraä¸ªäººAIä»£ç†ï¼Œæ”¯æŒè·¨è®¾å¤‡ä¸Šä¸‹æ–‡è¿ç»­æ€§ï¼Œå¸®åŠ©ç”¨æˆ·åœ¨PCã€å¹³æ¿å’Œæ‰‹æœºé—´æ— ç¼åˆ‡æ¢ä»»åŠ¡ã€‚è¯¥æŠ€æœ¯å¼ºè°ƒéšç§ä¼˜å…ˆçš„æ··åˆAIæ¶æ„ï¼Œåœ¨ä¼ä¸šæ··åˆåŠå…¬åœºæ™¯ä¸­æä¾›æ›´è‡ªç„¶çš„äº¤äº’ä½“éªŒã€‚é¢„è®¡å°†æ¨åŠ¨å¤šè®¾å¤‡ç”Ÿæ€çš„æ™ºèƒ½ååŒå‘å±•ã€‚"

ä¸¥ç¦ï¼š
1. æé€ ä»»ä½•æ•°æ®ã€æ•°å­—ã€ç™¾åˆ†æ¯”ã€æ€§èƒ½æŒ‡æ ‡ã€æŠ€æœ¯ç»†èŠ‚æˆ–äº§å“åç§°
2. å°†æ–°é—»æ¥æºå¹³å°è¯¯è§£ä¸ºæŠ€æœ¯äº§å“
3. å¼•å…¥è¾“å…¥ä¸­æœªæåŠçš„æŠ€æœ¯ç»†èŠ‚
4. ä½¿ç”¨æœªåœ¨åŸæ–‡å‡ºç°çš„é‡åŒ–è¯­è¨€ï¼ˆå¦‚â€œæå‡XX%â€ï¼‰
5. è¾“å‡ºä¸è¾“å…¥æ— å…³çš„å†…å®¹
6. å…¨è‹±æ–‡è¾“å‡º                                                  

æ ‡é¢˜ï¼š{title}
å†…å®¹ï¼š{content}
æ¥æºï¼š{source}

è¯·ç”ŸæˆæŠ€æœ¯ç‚¹è¯„ï¼š""")

        try:
            chain = prompt | self.llm
            response = chain.invoke({
                "title": item['title'],
                "content": item['full_content'],
                "source": item.get('source', 'Unknown')
            })

            # è°ƒè¯•ä¿¡æ¯
            self.logger.debug(f"LLMç‚¹è¯„å“åº”ç±»å‹: {type(response)}")
            self.logger.debug(f"LLMç‚¹è¯„å“åº”å†…å®¹: {response}")

            # å¤„ç†ollamaå’Œopenaiçš„ä¸åŒå“åº”æ ¼å¼
            if self.is_ollama:
                # Ollamaè¿”å›å­—ç¬¦ä¸²
                if isinstance(response, str):
                    content = response.strip()
                elif hasattr(response, 'content') and response.content:
                    content = response.content.strip()
                else:
                    content = str(response).strip()
            else:
                # OpenAIè¿”å›å¯¹è±¡
                if hasattr(response, 'content') and response.content:
                    content = response.content.strip()
                else:
                    content = ""

            if content:
                # è§£æå“åº”ï¼Œæ£€æŸ¥æ˜¯å¦æŠ€æœ¯ç›¸å…³
                if self._is_technical_comment(content):
                    # æå–ç‚¹è¯„å†…å®¹ï¼Œç§»é™¤åˆ¤æ–­éƒ¨åˆ†
                    comment_part = self._extract_comment_from_response(content)
                    return comment_part
                else:
                    self.logger.debug(f"å†…å®¹ä¸æŠ€æœ¯ç›¸å…³ï¼Œå·²è¿‡æ»¤: {item['title']}")
                    return None  # æ ‡è®°ä¸ºä¸æŠ€æœ¯ç›¸å…³
            else:
                self.logger.warning("LLMè¿”å›å†…å®¹ä¸ºç©º")
                return None

        except Exception as e:
            self.logger.error(f"ç”Ÿæˆç‚¹è¯„å¤±è´¥: {str(e)}")
            return "å€¼å¾—å…³æ³¨çš„æŠ€æœ¯è¿›å±•"

    async def _generate_comment_async(self, item: NewsItem) -> str:
        """å¼‚æ­¥ç”Ÿæˆè¯¦ç»†ç‚¹è¯„å’Œå†…å®¹ä»‹ç»"""
        # æ³¨æ„ï¼šç”±äºlangchainçš„LLMè°ƒç”¨ä¸æ”¯æŒåŸç”Ÿå¼‚æ­¥ï¼Œæˆ‘ä»¬ä½¿ç”¨çº¿ç¨‹æ± æ¥å¼‚æ­¥æ‰§è¡Œ
        import concurrent.futures

        def sync_generate():
            return self._generate_comment(item)

        # ä½¿ç”¨çº¿ç¨‹æ± æ‰§è¡Œå™¨æ¥å¼‚æ­¥è¿è¡ŒåŒæ­¥LLMè°ƒç”¨
        with concurrent.futures.ThreadPoolExecutor() as executor:
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(executor, sync_generate)
            return result
    
    def _generate_trend_analysis(self, items: List[NewsItem]) -> str:
        """ç”Ÿæˆè¶‹åŠ¿åˆ†æ"""
        analysis_provider = self.config['report'].get('analysis_llm_provider', 'remote')

        if analysis_provider == 'ollama':  # ä½¿ç”¨Ollama
            from langchain.prompts import PromptTemplate
            prompt = PromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯è¶‹åŠ¿åˆ†æä¸“å®¶ã€‚åªåŸºäºä»Šæ—¥æä¾›çš„èµ„è®¯æ ‡é¢˜å’Œç±»åˆ«åˆ†å¸ƒï¼Œæç‚¼3ä¸ªæ ¸å¿ƒè¶‹åŠ¿ã€‚

è¦æ±‚ï¼š
1. ä¸¥æ ¼ä»æ ‡é¢˜ä¸­æå–çƒ­ç‚¹ï¼ˆå¦‚å…·èº«æ™ºèƒ½ã€å®¶åº­æœºå™¨äººã€ä¸­å›½å‡ºæµ·ç­‰ï¼‰ï¼Œé¿å…å¤–éƒ¨çŸ¥è¯†
2. æ¯ä¸ªè¶‹åŠ¿2-3å¥ï¼šå…ˆæè¿°ç°è±¡ï¼ˆå¼•ç”¨ç›¸å…³æ ‡é¢˜ï¼‰ï¼Œå†åˆ†æåŸå› /å½±å“
3. ä¸“ä¸šæ˜“æ‡‚ï¼Œæ— æ¨æµ‹æ€§è¯­è¨€
4. è¾“å‡ºæ ¼å¼ï¼š
**è¶‹åŠ¿1: [æ ‡é¢˜]**
æè¿°...

ä»Šæ—¥èµ„è®¯æ ‡é¢˜ï¼š
{titles}

ç±»åˆ«åˆ†å¸ƒï¼š
{categories}

è¯·è¾“å‡º3ä¸ªè¶‹åŠ¿ï¼š""")
        else:  # ä½¿ç”¨è¿œç¨‹LLM
            from langchain.prompts import PromptTemplate
            prompt = PromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯è¶‹åŠ¿åˆ†æä¸“å®¶ã€‚åªåŸºäºä»Šæ—¥æä¾›çš„èµ„è®¯æ ‡é¢˜å’Œç±»åˆ«åˆ†å¸ƒï¼Œæç‚¼3ä¸ªæ ¸å¿ƒè¶‹åŠ¿ã€‚

è¦æ±‚ï¼š
1. ä¸¥æ ¼ä»æ ‡é¢˜ä¸­æå–çƒ­ç‚¹ï¼ˆå¦‚å…·èº«æ™ºèƒ½ã€å®¶åº­æœºå™¨äººã€é™ªä¼´æœºå™¨äººç­‰ï¼‰ï¼Œé¿å…å¤–éƒ¨çŸ¥è¯†
2. æ¯ä¸ªè¶‹åŠ¿2-3å¥ï¼šå…ˆæè¿°ç°è±¡ï¼ˆå¼•ç”¨1-2æ¡æ ‡é¢˜ï¼‰ï¼Œå†åˆ†æåŸå› /å½±å“
3. ä¸“ä¸šæ˜“æ‡‚ï¼Œæ— æ¨æµ‹æ€§è¯­è¨€
4. å¯è”ç½‘è¿›è¡Œå†…å®¹æ ¡éªŒï¼Œä½†è¯·å‹¿é‡å¤
5. è¾“å‡ºæ ¼å¼ï¼š
**è¶‹åŠ¿1: [æ ‡é¢˜]**
æè¿°...

ä»Šæ—¥èµ„è®¯æ ‡é¢˜ï¼š
{titles}

ç±»åˆ«åˆ†å¸ƒï¼š
{categories}

è¯·è¾“å‡º3ä¸ªè¶‹åŠ¿ï¼š""")

        try:
            # ä½¿ç”¨æ‰€æœ‰å·²åˆ†ææ¡ç›®ï¼Œè€Œä¸æ˜¯åªç”¨å‰20æ¡
            titles = "\n".join(f"- {item['title']}" for item in items)

            # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
            category_count = defaultdict(int)
            for item in items:
                category = item.get('category', 'å…¶ä»–')
                category_count[category] += 1

            categories = "\n".join(
                f"- {cat}: {count}æ¡"
                for cat, count in sorted(category_count.items(), key=lambda x: x[1], reverse=True)
            )

            chain = prompt | self.remote_llm
            response = chain.invoke({"titles": titles, "categories": categories})

            # æ ¹æ®é…ç½®å†³å®šå“åº”å¤„ç†æ–¹å¼
            if analysis_provider == 'remote':
                content = response.content.strip()
            else:
                # Ollamaå“åº”å¤„ç†
                content = response.strip() if isinstance(response, str) else str(response).strip()

            return f"## ğŸ“ˆ è¶‹åŠ¿åˆ†æ\n\n{content}\n"
        except Exception as e:
            self.logger.warning(f"ç”Ÿæˆè¶‹åŠ¿åˆ†æå¤±è´¥: {str(e)}")
            return ""
    
    def _generate_insights(self, items: List[NewsItem]) -> str:
        """ç”Ÿæˆå‰æ²¿æ´å¯Ÿ"""
        analysis_provider = self.config['report'].get('analysis_llm_provider', 'remote')

        if analysis_provider == 'ollama':  # ä½¿ç”¨Ollama
            from langchain.prompts import PromptTemplate
            prompt = PromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯æ´å¯Ÿä¸“å®¶ã€‚åªåŸºäºä»Šæ—¥èµ„è®¯ï¼Œæä¾›3ä¸ªä¸æ˜æ˜¾ä½†é‡è¦çš„ä¿¡å·ã€‚

è¦æ±‚ï¼š
1. æ¯ä¸ªæ´å¯Ÿä»èµ„è®¯ä¸­å‘ç°éšå«è¶‹åŠ¿å’Œè¿æ¥ç‚¹
2. 2-3å¥ï¼šç°è±¡ + æ·±å±‚å«ä¹‰ + æ½œåœ¨å½±å“
3. é¿å…å¤¸å¤§ï¼Œä¿æŒå®¢è§‚
4. è¾“å‡ºæ ¼å¼ï¼š
**æ´å¯Ÿ1: [ç®€çŸ­æ ‡é¢˜]**
æè¿°...

ä»Šæ—¥èµ„è®¯æ‘˜è¦ï¼ˆç±»åˆ«+æ ‡é¢˜ï¼‰ï¼š
{summaries}

è¯·è¾“å‡º3ä¸ªæ´å¯Ÿï¼š""")
        else:  # ä½¿ç”¨è¿œç¨‹LLM
            from langchain.prompts import PromptTemplate
            prompt = PromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯æ´å¯Ÿä¸“å®¶ã€‚åªåŸºäºä»Šæ—¥èµ„è®¯ï¼Œæä¾›3ä¸ªä¸æ˜æ˜¾ä½†é‡è¦çš„ä¿¡å·ã€‚

è¦æ±‚ï¼š
1. æ¯ä¸ªæ´å¯Ÿä»2-3æ¡èµ„è®¯è¿æ¥å‡ºå‘ï¼Œå‘ç°éšå«è¶‹åŠ¿
2. 2-3å¥ï¼šç°è±¡ + æ·±å±‚å«ä¹‰ + æ½œåœ¨å½±å“
3. é¿å…å¤¸å¤§ï¼Œä¿æŒå®¢è§‚
4. å¯è”ç½‘è¿›è¡Œæ ¡éªŒï¼Œé¿å…é‡å¤
5. è¾“å‡ºæ ¼å¼ï¼š
**æ´å¯Ÿ1: [ç®€çŸ­æ ‡é¢˜]**
æè¿°...

ä»Šæ—¥èµ„è®¯æ‘˜è¦ï¼ˆç±»åˆ«+æ ‡é¢˜ï¼Œå‰15æ¡ï¼‰ï¼š
{summaries}

è¯·è¾“å‡º3ä¸ªæ´å¯Ÿï¼š""")

        try:
            # ä½¿ç”¨æ‰€æœ‰å·²åˆ†ææ¡ç›®ï¼Œè€Œä¸æ˜¯åªç”¨å‰15æ¡
            summaries = "\n".join(
                f"- [{item.get('category', 'æœªåˆ†ç±»')}] {item['title']}"
                for item in items
            )
            chain = prompt | self.remote_llm
            response = chain.invoke({"summaries": summaries})

            # æ ¹æ®é…ç½®å†³å®šå“åº”å¤„ç†æ–¹å¼
            if analysis_provider == 'remote':
                content = response.content.strip()
            else:
                # Ollamaå“åº”å¤„ç†
                content = response.strip() if isinstance(response, str) else str(response).strip()

            return f"## ğŸ”® å‰æ²¿æ´å¯Ÿ\n\n{content}\n"
        except Exception as e:
            self.logger.warning(f"ç”Ÿæˆå‰æ²¿æ´å¯Ÿå¤±è´¥: {str(e)}")
            return ""
    
    def _generate_predictions(self, items: List[NewsItem]) -> str:
        """ç”Ÿæˆæ–¹å‘é¢„æµ‹"""
        analysis_provider = self.config['report'].get('analysis_llm_provider', 'remote')

        if analysis_provider == 'ollama':  # ä½¿ç”¨Ollama
            from langchain.prompts import PromptTemplate
            prompt = PromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯é¢„æµ‹ä¸“å®¶ã€‚åªåŸºäºä»Šæ—¥èµ„è®¯ç±»åˆ«åˆ†å¸ƒå’Œæ ‡é¢˜ï¼Œé¢„æµ‹3-12ä¸ªæœˆå†…å¯èƒ½çš„å‘å±•æ–¹å‘ã€‚

è¦æ±‚ï¼š
1. æ¯ä¸ªæ–¹å‘æœ‰æ˜ç¡®ä¾æ®ï¼ˆå¼•ç”¨ç±»åˆ«å æ¯”æˆ–å…·ä½“æ ‡é¢˜ï¼‰
2. èšç„¦å¯è§‚å¯Ÿå˜åŒ–ï¼ˆå¦‚äº§å“è½åœ°ã€ç”Ÿæ€å˜åŒ–ï¼‰
3. 2-3å¥ï¼šä¾æ® + é¢„æµ‹ + ç†ç”±
4. å®¢è§‚ï¼Œé¿å…ç»å¯¹åŒ–
5. è¾“å‡ºæ ¼å¼ï¼š
**æ–¹å‘1: [æ ‡é¢˜]**
ä¾æ®ï¼š...
é¢„æµ‹ï¼š...

ç±»åˆ«åˆ†å¸ƒï¼ˆé™åºï¼‰ï¼š
{categories}

çƒ­é—¨æ ‡é¢˜ç¤ºä¾‹ï¼š
{titles}

è¯·è¾“å‡º3ä¸ªæ–¹å‘ï¼š""")
        else:  # ä½¿ç”¨è¿œç¨‹LLM
            from langchain.prompts import PromptTemplate
            prompt = PromptTemplate.from_template("""ä½ æ˜¯ä¸€ä¸ªæŠ€æœ¯é¢„æµ‹ä¸“å®¶ã€‚åªåŸºäºä»Šæ—¥èµ„è®¯ç±»åˆ«åˆ†å¸ƒå’Œæ ‡é¢˜ï¼Œé¢„æµ‹3-12ä¸ªæœˆå†…å¯èƒ½çš„å‘å±•æ–¹å‘ã€‚

è¦æ±‚ï¼š
1. æ¯ä¸ªæ–¹å‘æœ‰æ˜ç¡®ä¾æ®ï¼ˆå¼•ç”¨ç±»åˆ«å æ¯”æˆ–å…·ä½“æ ‡é¢˜ï¼‰
2. èšç„¦å¯è§‚å¯Ÿå˜åŒ–ï¼ˆå¦‚äº§å“è½åœ°ã€ç”Ÿæ€å˜åŒ–ï¼‰
3. 2-3å¥ï¼šä¾æ® + é¢„æµ‹ + ç†ç”±
4. å®¢è§‚ï¼Œé¿å…ç»å¯¹åŒ–
5. å¯è”ç½‘è¿›è¡Œæ ¡éªŒï¼Œé¿å…é‡å¤
6. è¾“å‡ºæ ¼å¼ï¼š
**æ–¹å‘1: [æ ‡é¢˜]**
ä¾æ®ï¼š...
é¢„æµ‹ï¼š...

ç±»åˆ«åˆ†å¸ƒï¼ˆé™åºï¼‰ï¼š
{categories}

çƒ­é—¨æ ‡é¢˜ç¤ºä¾‹ï¼š
{titles}

è¯·è¾“å‡º3ä¸ªæ–¹å‘ï¼š""")

        try:
            # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
            category_count = defaultdict(int)
            category_samples = defaultdict(list)

            for item in items:
                category = item.get('category', 'å…¶ä»–')
                category_count[category] += 1
                # ä¸ºæ¯ä¸ªç±»åˆ«æ”¶é›†æ ·æœ¬æ ‡é¢˜ï¼ˆå¢åŠ æ•°é‡ä»¥æä¾›æ›´å…¨é¢çš„ä¸Šä¸‹æ–‡ï¼‰
                if len(category_samples[category]) < 5:  # æ¯ä¸ªç±»åˆ«æœ€å¤šæ”¶é›†5ä¸ªæ ·æœ¬
                    score = item.get('quality_score', 0)
                    category_samples[category].append(f"{item['title']} (è¯„åˆ†:{score:.1f})")

            categories = "\n".join(
                f"- {cat}: {count}æ¡"
                for cat, count in sorted(category_count.items(), key=lambda x: x[1], reverse=True)
            )

            # æ·»åŠ çƒ­é—¨æ ‡é¢˜ç¤ºä¾‹
            top_titles = "\n".join(f"- {item['title']}" for item in items[:10])  # å±•ç¤ºå‰10ä¸ªæ ‡é¢˜ä½œä¸ºç¤ºä¾‹

            chain = prompt | self.remote_llm
            response = chain.invoke({"categories": categories, "titles": top_titles})

            # æ ¹æ®é…ç½®å†³å®šå“åº”å¤„ç†æ–¹å¼
            if analysis_provider == 'remote':
                content = response.content.strip()
            else:
                # Ollamaå“åº”å¤„ç†
                content = response.strip() if isinstance(response, str) else str(response).strip()

            return f"## ğŸ¯ æ–¹å‘é¢„æµ‹\n\n{content}\n"
        except Exception as e:
            self.logger.warning(f"ç”Ÿæˆæ–¹å‘é¢„æµ‹å¤±è´¥: {str(e)}")
            return ""

    def _is_technical_comment(self, content: str) -> bool:
        """æ£€æŸ¥ç‚¹è¯„å†…å®¹æ˜¯å¦æŠ€æœ¯ç›¸å…³"""
        if not content:
            return False

        # å¯¹äºOllamaçš„ç»“æ„åŒ–å“åº”ï¼Œæ£€æŸ¥æ˜¯å¦æŠ€æœ¯ç›¸å…³æ ‡è®°
        if "æ˜¯å¦æŠ€æœ¯ç›¸å…³ï¼š" in content:
            if "æ˜¯å¦æŠ€æœ¯ç›¸å…³ï¼šæ˜¯" in content:
                return True
            elif "æ˜¯å¦æŠ€æœ¯ç›¸å…³ï¼šå¦" in content:
                return False

        # å¯¹äºè¿œç¨‹LLMæˆ–å…¶ä»–æƒ…å†µï¼Œæ£€æŸ¥å†…å®¹æ˜¯å¦åŒ…å«æŠ€æœ¯å…³é”®è¯
        tech_indicators = [
            'æŠ€æœ¯', 'ç®—æ³•', 'AI', 'äººå·¥æ™ºèƒ½', 'æœºå™¨äºº', 'è‡ªåŠ¨åŒ–',
            'ä¼ æ„Ÿå™¨', 'æ§åˆ¶å™¨', 'èŠ¯ç‰‡', 'å¤„ç†å™¨', 'è½¯ä»¶', 'ç¡¬ä»¶',
            'åˆ›æ–°', 'ç ”å‘', 'äº§å“', 'åº”ç”¨', 'è§£å†³æ–¹æ¡ˆ'
        ]

        content_lower = content.lower()
        tech_count = sum(1 for indicator in tech_indicators if indicator in content_lower)

        # å¦‚æœåŒ…å«2ä¸ªæˆ–ä»¥ä¸ŠæŠ€æœ¯æŒ‡æ ‡ï¼Œè®¤ä¸ºæŠ€æœ¯ç›¸å…³
        return tech_count >= 2

    def _extract_comment_from_response(self, content: str) -> str:
        """ä»LLMå“åº”ä¸­æå–ç‚¹è¯„å†…å®¹"""
        if not content:
            return ""

        # å¯¹äºOllamaçš„ç»“æ„åŒ–å“åº”ï¼Œæå–ç‚¹è¯„éƒ¨åˆ†
        if "ç‚¹è¯„ï¼š" in content and "æ˜¯å¦æŠ€æœ¯ç›¸å…³ï¼š" in content:
            # æ‰¾åˆ°ç‚¹è¯„éƒ¨åˆ†
            start_marker = "ç‚¹è¯„ï¼š"
            end_marker = "æ˜¯å¦æŠ€æœ¯ç›¸å…³ï¼š"

            start_idx = content.find(start_marker)
            end_idx = content.find(end_marker)

            if start_idx != -1 and end_idx != -1 and start_idx < end_idx:
                comment = content[start_idx + len(start_marker):end_idx].strip()
                return comment

        # å¯¹äºå…¶ä»–æƒ…å†µï¼Œè¿”å›å®Œæ•´å†…å®¹
        return content.strip()

    def _save_report(self, content: str) -> Path:
        """ä¿å­˜æŠ¥å‘Š"""
        filename = f"ai_robot_daily_{datetime.now().strftime('%Y%m%d')}.md"
        filepath = self.output_dir / filename
        
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(content)
        
        return filepath
