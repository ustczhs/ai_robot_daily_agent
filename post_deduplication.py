#!/usr/bin/env python3
"""
æ—¥æŠ¥åå¤„ç†å»é‡è„šæœ¬ - ä½¿ç”¨ Ollama LLM å¯¹å·²ç”Ÿæˆçš„æ—¥æŠ¥è¿›è¡Œå»é‡
"""

import re
import yaml
import logging
from pathlib import Path
from typing import List, Dict, Optional
from dataclasses import dataclass
from langchain_ollama import OllamaLLM
from langchain.prompts import PromptTemplate


@dataclass
class NewsItem:
    """æ–°é—»æ¡ç›®æ•°æ®ç±»"""
    title: str
    content: str
    source: str
    url: str
    score: float
    category: str
    published_date: str
    raw_markdown: str  # å­˜å‚¨å®Œæ•´çš„åŸå§‹ markdown æ ¼å¼


class PostDeduplicator:
    """æ—¥æŠ¥åå¤„ç†å»é‡å™¨"""

    def __init__(self, config_path: str = "config/config.yaml"):
        self.config = self._load_config(config_path)
        self.llm = self._init_llm()
        self.logger = logging.getLogger(__name__)

        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(
            level=logging.INFO,  # åªæ˜¾ç¤ºé‡è¦ä¿¡æ¯
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )

    def _load_config(self, config_path: str) -> dict:
        """åŠ è½½é…ç½®æ–‡ä»¶"""
        with open(config_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)

    def _init_llm(self) -> OllamaLLM:
        """åˆå§‹åŒ– Ollama LLM"""
        llm_config = self.config['llm']
        if llm_config['provider'].lower() != 'ollama':
            raise ValueError("æ­¤è„šæœ¬éœ€è¦ä½¿ç”¨ Ollama LLMï¼Œè¯·åœ¨ config.yaml ä¸­è®¾ç½® provider: ollama")

        return OllamaLLM(
            model=llm_config['model'],
            base_url=llm_config.get('ollama_base_url', 'http://localhost:11434'),
            temperature=0.1  # å»é‡éœ€è¦è¾ƒä½æ¸©åº¦ä»¥ä¿è¯ä¸€è‡´æ€§
        )

    def parse_markdown_report(self, file_path: str) -> List[NewsItem]:
        """è§£æ markdown æŠ¥å‘Šæ–‡ä»¶ï¼Œæå–æ–°é—»æ¡ç›®"""
        self.logger.info(f"å¼€å§‹è§£ææŠ¥å‘Šæ–‡ä»¶: {file_path}")

        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()

        items = []
        current_category = ""

        # æŒ‰è¡Œåˆ†å‰²å†…å®¹
        lines = content.split('\n')
        i = 0

        while i < len(lines):
            line = lines[i].strip()

            # æ£€æµ‹æŠ€æœ¯åˆ†ç±»
            if line.startswith('### '):
                current_category = line[4:].strip()
                self.logger.debug(f"å‘ç°åˆ†ç±»: {current_category}")
                i += 1
                continue

            # æ£€æµ‹æ–°é—»æ¡ç›®å¼€å§‹ï¼ˆæ•°å­—ç¼–å· + æ ‡é¢˜ï¼‰
            if re.match(r'^\d+\.\s+\*\*', line):
                self.logger.debug(f"æ‰¾åˆ°æ–°é—»æ¡ç›®: {line[:50]}...")
                item = self._parse_news_item(lines, i, current_category)
                if item:
                    items.append(item)
                    self.logger.debug(f"æˆåŠŸè§£ææ–°é—»: {item.title[:30]}...")
                    # è·³è¿‡å·²å¤„ç†çš„è¡Œ
                    while i < len(lines) and lines[i].strip():
                        i += 1
                else:
                    self.logger.debug(f"è§£ææ–°é—»å¤±è´¥: {line[:50]}...")
                    i += 1
            else:
                i += 1

        self.logger.info(f"è§£æå®Œæˆï¼Œå…±æå– {len(items)} æ¡æ–°é—»")
        return items

    def _parse_news_item(self, lines: List[str], start_idx: int, category: str) -> Optional[NewsItem]:
        """è§£æå•ä¸ªæ–°é—»æ¡ç›®"""
        try:
            # æ”¶é›†å®Œæ•´çš„æ¡ç›®æ–‡æœ¬ï¼ˆç”¨äºä¿æŒåŸå§‹æ ¼å¼ï¼‰
            raw_lines = []
            i = start_idx

            # ç¬¬ä¸€è¡Œï¼šç¼–å· + æ ‡é¢˜ + é“¾æ¥
            title_line = lines[i].strip()
            raw_lines.append(title_line)

            # ç¬¬äºŒè¡Œï¼šé“¾æ¥è¡Œï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            i += 1
            if i < len(lines) and '<a href=' in lines[i]:
                raw_lines.append(lines[i])
                i += 1

            # åç»­è¡Œï¼šæ¥æºã€æ—¶é—´ã€è¯„åˆ†ã€ç®€ä»‹
            for _ in range(4):  # é€šå¸¸æœ‰4è¡Œå…ƒæ•°æ®
                if i < len(lines) and lines[i].strip():
                    raw_lines.append(lines[i])
                    i += 1

            # åˆå¹¶æ‰€æœ‰åŸå§‹è¡Œ
            raw_markdown = '\n'.join(raw_lines)

            # è§£æå…³é”®ä¿¡æ¯ç”¨äºå»é‡åˆ¤æ–­
            title_line = raw_lines[0]
            match = re.search(r'\d+\.\s+\*\*\[([^\]]+)\]\[([^\]]+)\]\*\*', title_line)
            if not match:
                match = re.search(r'\d+\.\s+\*\*(.+?)\*\*\[([^\]]+)\]\*\*', title_line)
                if not match:
                    return None
                title = match.group(1).strip()
                url = match.group(2).strip()
            else:
                title = match.group(1).strip()
                url = match.group(2).strip()

            # ä»åŸå§‹æ–‡æœ¬ä¸­æå–å…¶ä»–ä¿¡æ¯
            source = "æœªçŸ¥"
            published_date = ""
            score = 5.0
            content = ""

            for line in raw_lines[1:]:
                if 'ğŸ“° æ¥æº:' in line:
                    source_match = re.search(r'ğŸ“° æ¥æº:\s*(.+)', line)
                    if source_match:
                        source = source_match.group(1).strip()
                elif 'ğŸ•’ å‘å¸ƒæ—¶é—´:' in line:
                    date_match = re.search(r'ğŸ•’ å‘å¸ƒæ—¶é—´:\s*(.+)', line)
                    if date_match:
                        published_date = date_match.group(1).strip()
                elif 'â­ è¯„åˆ†:' in line:
                    score_match = re.search(r'â­ è¯„åˆ†:\s*([\d.]+)/10', line)
                    if score_match:
                        score = float(score_match.group(1))
                elif 'ğŸ’¬ ç®€ä»‹:' in line:
                    content_match = re.search(r'ğŸ’¬ ç®€ä»‹:\s*(.+)', line)
                    if content_match:
                        content = content_match.group(1).strip()

            return NewsItem(
                title=title,
                content=content,
                source=source,
                url=url,
                score=score,
                category=category,
                published_date=published_date,
                raw_markdown=raw_markdown
            )

        except Exception as e:
            self.logger.warning(f"è§£ææ–°é—»æ¡ç›®å¤±è´¥: {str(e)}")
            return None

    def deduplicate_news(self, items: List[NewsItem]) -> List[NewsItem]:
        """ä½¿ç”¨ LLM å¯¹æ–°é—»è¿›è¡Œå»é‡"""
        self.logger.info(f"å¼€å§‹ LLM å»é‡å¤„ç†ï¼Œå…± {len(items)} æ¡æ–°é—»")

        if len(items) <= 1:
            return items

        deduplicated = []
        removed_count = 0

        # å¯¹æ¯æ¡æ–°é—»ï¼Œæ£€æŸ¥æ˜¯å¦ä¸å·²ä¿ç•™çš„æ–°é—»é‡å¤
        for i, item in enumerate(items):
            self.logger.info(f"æ£€æŸ¥ {i+1}/{len(items)}: {item.title[:50]}...")

            is_duplicate = False
            duplicate_with = None

            # ä¸å·²ä¿ç•™çš„æ–°é—»æ¯”è¾ƒ
            for existing in deduplicated:
                if self._is_duplicate(item, existing):
                    is_duplicate = True
                    duplicate_with = existing.title[:30] + "..."
                    break

            if is_duplicate:
                self.logger.debug(f"  âœ— é‡å¤ (ä¸: {duplicate_with})")
                removed_count += 1
            else:
                deduplicated.append(item)
                self.logger.debug(f"  âœ“ ä¿ç•™")

        self.logger.info(f"å»é‡å®Œæˆ: åŸå§‹ {len(items)} æ¡ï¼Œå»é™¤ {removed_count} æ¡é‡å¤ï¼Œä¿ç•™ {len(deduplicated)} æ¡")
        return deduplicated

    def _is_duplicate(self, item1: NewsItem, item2: NewsItem) -> bool:
        """åˆ¤æ–­ä¸¤æ¡æ–°é—»æ˜¯å¦é‡å¤"""
        prompt = PromptTemplate.from_template("""
è¯·åˆ¤æ–­ä»¥ä¸‹ä¸¤æ¡æ–°é—»æ˜¯å¦æè¿°ç›¸åŒçš„æ ¸å¿ƒäº‹ä»¶ã€‚

æ–°é—»Aï¼š
æ ‡é¢˜ï¼š{title_a}
æ¥æºï¼š{source_a}
ç®€ä»‹ï¼š{content_a}

æ–°é—»Bï¼š
æ ‡é¢˜ï¼š{title_b}
æ¥æºï¼š{source_b}
ç®€ä»‹ï¼š{content_b}

è¯·åªå›ç­”"æ˜¯"æˆ–"å¦"ï¼Œåé¢ç®€è¦è¯´æ˜ç†ç”±ï¼ˆä¸è¶…è¿‡30å­—ï¼‰ã€‚

åˆ¤æ–­æ ‡å‡†ï¼š
- å¦‚æœæè¿°çš„æ˜¯åŒä¸€äº‹ä»¶ã€åŒä¸€äº§å“å‘å¸ƒã€åŒä¸€å…¬å¸åŠ¨æ€ï¼Œåˆ™ä¸º"æ˜¯"
- å¦‚æœåªæ˜¯ç›¸å…³ä½†ä¸åŒçš„äº‹ä»¶ï¼Œåˆ™ä¸º"å¦"
- å³ä½¿æ¥æºä¸åŒï¼Œåªè¦æ ¸å¿ƒäº‹ä»¶ç›¸åŒå°±æ˜¯é‡å¤

å›ç­”æ ¼å¼ï¼š
[æ˜¯/å¦] ç†ç”±
""")

        try:
            response = self.llm.invoke(prompt.format(
                title_a=item1.title,
                source_a=item1.source,
                content_a=item1.content[:200],  # é™åˆ¶å†…å®¹é•¿åº¦
                title_b=item2.title,
                source_b=item2.source,
                content_b=item2.content[:200]
            ))

            response = response.strip()

            # è§£æå“åº”
            if response.upper().startswith('æ˜¯') or response.upper().startswith('YES'):
                return True
            elif response.upper().startswith('å¦') or response.upper().startswith('NO'):
                return False
            else:
                # å¦‚æœæ— æ³•è§£æï¼Œä¿å®ˆå¤„ç†ä¸ºä¸é‡å¤
                self.logger.warning(f"LLM å“åº”æ— æ³•è§£æ: {response}")
                return False

        except Exception as e:
            self.logger.error(f"LLM åˆ¤æ–­é‡å¤å¤±è´¥: {str(e)}")
            return False  # å‡ºé”™æ—¶ä¿å®ˆå¤„ç†ä¸ºä¸é‡å¤

    def generate_deduplicated_report(self, original_path: str, deduplicated_items: List[NewsItem]) -> str:
        """ç”Ÿæˆå»é‡åçš„æŠ¥å‘Šæ–‡ä»¶"""
        self.logger.info("ç”Ÿæˆå»é‡åçš„æŠ¥å‘Šæ–‡ä»¶...")

        # è¯»å–åŸå§‹æ–‡ä»¶
        with open(original_path, 'r', encoding='utf-8') as f:
            original_content = f.read()

        # ç”Ÿæˆæ–°æ–‡ä»¶å
        original_path_obj = Path(original_path)
        new_filename = original_path_obj.stem + "_deduplicated" + original_path_obj.suffix
        new_path = original_path_obj.parent / new_filename

        # æŒ‰åˆ†ç±»é‡æ–°ç»„ç»‡å†…å®¹
        category_items = {}
        for item in deduplicated_items:
            if item.category not in category_items:
                category_items[item.category] = []
            category_items[item.category].append(item)

        # æ„å»ºæ–°çš„æŠ¥å‘Šå†…å®¹
        lines = original_content.split('\n')
        new_lines = []
        i = 0

        while i < len(lines):
            line = lines[i]

            # å¤åˆ¶æ ‡é¢˜å’Œæ¦‚è§ˆéƒ¨åˆ†
            if line.startswith('# ') or line.startswith('**æ—¥æœŸ**') or line.startswith('---') or line.startswith('## ğŸ“Š'):
                new_lines.append(line)
                i += 1
                continue

            # å¤„ç†æŠ€æœ¯åˆ†ç±»
            if line.startswith('### '):
                category = line[4:].strip()
                new_lines.append(line)

                # å¦‚æœè¯¥åˆ†ç±»æœ‰æ–°é—»ï¼Œåˆ™é‡æ–°ç”Ÿæˆ
                if category in category_items and category_items[category]:
                    items = category_items[category]
                    self.logger.info(f"é‡æ–°ç”Ÿæˆåˆ†ç±» {category}: {len(items)} æ¡æ–°é—»")

                    # è·³è¿‡åŸå§‹å†…å®¹ï¼Œç”Ÿæˆæ–°å†…å®¹
                    i = self._skip_category_content(lines, i + 1)

                    # ç”Ÿæˆæ–°çš„æ–°é—»æ¡ç›®
                    for j, item in enumerate(items, 1):
                        new_lines.extend(self._format_news_item(item, j))

                else:
                    # å¦‚æœåˆ†ç±»ä¸ºç©ºï¼Œåˆ é™¤æ•´ä¸ªåˆ†ç±»
                    self.logger.info(f"åˆ†ç±» {category} æ— æ–°é—»ï¼Œåˆ é™¤")
                    i = self._skip_category_content(lines, i + 1)

            else:
                new_lines.append(line)
                i += 1

        # æ›´æ–°æ¦‚è§ˆç»Ÿè®¡
        new_content = '\n'.join(new_lines)
        new_content = self._update_overview_stats(new_content, deduplicated_items)

        # å†™å…¥æ–°æ–‡ä»¶
        with open(new_path, 'w', encoding='utf-8') as f:
            f.write(new_content)

        self.logger.info(f"å»é‡åæŠ¥å‘Šå·²ç”Ÿæˆ: {new_path}")
        return str(new_path)

    def _skip_category_content(self, lines: List[str], start_idx: int) -> int:
        """è·³è¿‡åˆ†ç±»çš„å†…å®¹éƒ¨åˆ†"""
        i = start_idx
        while i < len(lines):
            line = lines[i].strip()
            # æ£€æµ‹ä¸‹ä¸€ä¸ªåˆ†ç±»æˆ–ç»“æŸ
            if line.startswith('### ') or line.startswith('## ğŸ”®') or line.startswith('---'):
                break
            i += 1
        return i

    def _format_news_item(self, item: NewsItem, number: int) -> List[str]:
        """æ ¼å¼åŒ–æ–°é—»æ¡ç›®ä¸º markdown - ä½¿ç”¨åŸå§‹æ ¼å¼å¹¶é‡æ–°ç¼–å·"""
        # ä½¿ç”¨åŸå§‹ markdownï¼Œä½†æ›´æ–°ç¼–å·
        lines = item.raw_markdown.split('\n')

        # æ›´æ–°ç¬¬ä¸€è¡Œçš„ç¼–å·
        if lines and re.match(r'^\d+\.', lines[0]):
            # æ›¿æ¢å¼€å¤´çš„æ•°å­—ç¼–å·
            lines[0] = re.sub(r'^\d+\.', f'{number}.', lines[0])

        # æ·»åŠ ç©ºè¡Œ
        lines.append("")

        return lines

    def _update_overview_stats(self, content: str, items: List[NewsItem]) -> str:
        """æ›´æ–°æŠ¥å‘Šå¼€å¤´çš„ç»Ÿè®¡ä¿¡æ¯"""
        # è®¡ç®—æ–°çš„ç»Ÿè®¡æ•°æ®
        total_news = len(items)
        categories = len(set(item.category for item in items))
        sources = len(set(item.source for item in items))

        # æ›¿æ¢æ¦‚è§ˆç»Ÿè®¡
        content = re.sub(
            r'- \*\*æ”¶é›†èµ„è®¯\*\*: \d+ æ¡',
            f'- **æ”¶é›†èµ„è®¯**: {total_news} æ¡',
            content
        )
        content = re.sub(
            r'- \*\*æŠ€æœ¯ç±»åˆ«\*\*: \d+ ä¸ª',
            f'- **æŠ€æœ¯ç±»åˆ«**: {categories} ä¸ª',
            content
        )
        content = re.sub(
            r'- \*\*ä¿¡æ¯æ¥æº\*\*: \d+ ä¸ª',
            f'- **ä¿¡æ¯æ¥æº**: {sources} ä¸ª',
            content
        )

        return content


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='æ—¥æŠ¥åå¤„ç†å»é‡è„šæœ¬')
    parser.add_argument('input_file', help='è¾“å…¥çš„æ—¥æŠ¥ markdown æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--config', default='config/config.yaml', help='é…ç½®æ–‡ä»¶è·¯å¾„')

    args = parser.parse_args()

    # åˆå§‹åŒ–å»é‡å™¨
    deduplicator = PostDeduplicator(args.config)

    # è§£ææŠ¥å‘Š
    items = deduplicator.parse_markdown_report(args.input_file)

    # å»é‡å¤„ç†
    deduplicated_items = deduplicator.deduplicate_news(items)

    # ç”Ÿæˆæ–°æŠ¥å‘Š
    output_path = deduplicator.generate_deduplicated_report(args.input_file, deduplicated_items)

    print("âœ… å»é‡å¤„ç†å®Œæˆ!")
    print(f"ğŸ“ åŸå§‹æ–‡ä»¶: {args.input_file}")
    print(f"ğŸ“ å»é‡æ–‡ä»¶: {output_path}")
    print(f"ğŸ“Š ç»Ÿè®¡: {len(items)} â†’ {len(deduplicated_items)} æ¡æ–°é—»")


if __name__ == "__main__":
    main()
